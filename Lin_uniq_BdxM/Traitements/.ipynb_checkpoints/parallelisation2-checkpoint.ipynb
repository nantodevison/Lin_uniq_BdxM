{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PARALLELISATION 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys #c'est pas propre mais pour le moment pour importer mes modules perso dans le notebook je ne sais pas faire\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Lin_uniq_BdxM\\Lin_uniq_BdxM\\Traitements')\n",
    "import Connexion_Transfert as ct\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, json\n",
    "from copy import copy, deepcopy\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from Outils import creer_graph, plus_proche_voisin,nb_noeud_unique_troncon_continu,verif_index, gp_changer_nom_geom\n",
    "from shapely.wkt import dumps, loads\n",
    "\n",
    "from Simplifier_Rdpt import creer_dico_noeud_rdpt,simplifier_noeud_rdpt,maj_graph_rdpt, donnees_tot_rd_pt\n",
    "import Estim_trafic as et\n",
    "import Comptage as Cpt\n",
    "import Affectation_pt_comptage as ap\n",
    "import Voies_Cat4 as v4\n",
    "from MMM import import_fichiers_mmm\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rappel des donnees necessaires\n",
    "bati_ligne_proche=pd.read_json(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\paralelisation3.json')\n",
    "bati_ligne_proche['point_proche']=bati_ligne_proche.point_proche.apply(lambda x : loads(x))\n",
    "resultat=pd.read_json(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\trajet_bati_cat123.json')\n",
    "resultat.trajet_court=resultat.trajet_court.apply(lambda x : tuple(x))\n",
    "f=open(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\df_tt_trajet_save.json','r')\n",
    "retour_dict=json.loads(f.read())\n",
    "f.close()\n",
    "dico_df_tt_trajet={k:pd.DataFrame.from_dict(v) for k, v in retour_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ct.ConnexionBdd('local_otv') as c :\n",
    "    graph_filaire = gp.read_postgis('select * from linearisation_bm.graph_rhv_complet', c.connexionPsy)\n",
    "    graph_filaire_vertex=gp.read_postgis('select id,cnt,chk,ein,eout,the_geom as geom from linearisation_bm.graph_rhv_complet_vertices_pgr', c.connexionPsy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import du fichier de trafic\n",
    "gdf_traf_1234=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_1234_cpt.shp')\n",
    "#importdes voies non connues\n",
    "voies_nc=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\voie_non_affectees.shp')\n",
    "voies_nc['longueur']=voies_nc.geometry.apply(lambda x : round(x.length,1))\n",
    "ensemble_lignes=voies_nc.copy()\n",
    "#j'ai besoin de cette ligne car les source_target de gdf_traf_1234 sont diff√©rents de ceux de ensemble_lignes\n",
    "gdf_tot_eq_1234=graph_filaire.loc[graph_filaire.ident.isin(gdf_traf_1234.ident.tolist())]\n",
    "vertex_connus=list(set(gdf_tot_eq_1234.source.tolist()+gdf_tot_eq_1234.target.tolist()))\n",
    "vertex_impasse=[k for k, v in Counter(graph_filaire.source.tolist()+graph_filaire.target.tolist()).items() if v==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=resultat.index.max()+1\n",
    "liste_bati_erreur=[]\n",
    "for e,b in enumerate(bati_ligne_proche.ID.tolist()) : \n",
    "    if e%100==0:\n",
    "        print(f'nb bati traite : {e}, {datetime.now()}, {b}')\n",
    "    ident_proche_bati=str(bati_ligne_proche.loc[bati_ligne_proche['ID']==b].ident.to_numpy()[0])#risque si ident pas trouver d'IndexError\n",
    "    if ensemble_lignes.loc[ensemble_lignes['ident']==ident_proche_bati].empty :\n",
    "        resultat.loc[i]=[b,ident_proche_bati,np.NaN,np.NaN,'pas ident proche dans voies nc']\n",
    "        i+=1\n",
    "        continue\n",
    "    point_depart=bati_ligne_proche.loc[bati_ligne_proche['ID']==b].point_proche.values[0]\n",
    "    trajets=v4.ensemble_trajet(ident_proche_bati,point_depart,ensemble_lignes, vertex_connus, vertex_impasse, graph_filaire_vertex)\n",
    "    noeud_proche=trajets.noeud_proche\n",
    "    if ident_proche_bati in resultat.ident.to_numpy() :\n",
    "        df_find_existant=resultat.loc[(resultat['ident']==ident_proche_bati) & (resultat['noeud_proche']==noeud_proche)]\n",
    "        if not df_find_existant.empty:\n",
    "            resultat.loc[i]=[b,ident_proche_bati,noeud_proche,df_find_existant.trajet_court.values[0], 'Deduction_trajet-ident connu_noeud_proche connu',df_find_existant.noeud_cat3.values[0]]\n",
    "            i+=1\n",
    "        else : \n",
    "            trajets.df_trajet_cat3_grp_OD=dico_df_tt_trajet[ident_proche_bati]\n",
    "            trajets.maj_longueur_tot(trajets.df_trajet_cat3_grp_OD)\n",
    "            df_finale=trajets.df_trajet_cat3_grp_OD.loc[trajets.df_trajet_cat3_grp_OD.longueur_tot==trajets.df_trajet_cat3_grp_OD.longueur_tot.min()]\n",
    "            resultat.loc[i]=[b,ident_proche_bati,noeud_proche,tuple(df_finale.lignes.to_numpy()[0]), 'Deduction_trajet-ident connu_noeud_proche varie',df_finale.points.to_numpy()[0][-1]]\n",
    "            i+=1\n",
    "    elif ident_proche_bati in [b for a in resultat.loc[~resultat['trajet_court'].isna()].trajet_court.to_numpy() for b in a] :\n",
    "        resultat_equi=resultat.loc[resultat.trajet_court.apply(lambda x : ident_proche_bati in x if isinstance(x,tuple) else False)].iloc[0]\n",
    "        trajet_equi=resultat_equi.trajet_court\n",
    "        trajet_court=trajet_equi[trajet_equi.index(ident_proche_bati):] \n",
    "        resultat.loc[i]=[b,ident_proche_bati,trajets.src,trajet_court, 'Deduction_trajet-ident sur chemin',resultat_equi.noeud_cat3]\n",
    "        i+=1\n",
    "        resultat.loc[i]=[b,ident_proche_bati,trajets.tgt,trajet_court, 'Deduction_trajet-ident sur chemin',resultat_equi.noeud_cat3]\n",
    "        i+=1\n",
    "    else : \n",
    "        try :\n",
    "            trajets.calculs_trajets()\n",
    "        except v4.PasDeCheminCat3Error : \n",
    "            liste_bati_erreur.append(b)\n",
    "            continue\n",
    "        resultat.loc[i]=[b,ident_proche_bati,noeud_proche,trajets.trajet_court, 'Calcul_trajet',trajets.point_arrive]\n",
    "        i+=1\n",
    "        dico_df_tt_trajet[ident_proche_bati]=trajets.df_trajet_cat3_grp_OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#test sur une ligne\n",
    "ident_proche_bati=str(bati_ligne_proche.loc[bati_ligne_proche['ID']=='BATIMENT0000000257802004'].ident.to_numpy()[0])#risque si ident pas trouver d'IndexError\n",
    "point_depart=bati_ligne_proche.loc[bati_ligne_proche['ID']=='BATIMENT0000000257802004'].point_proche.values[0]\n",
    "trajets=v4.ensemble_trajet(ident_proche_bati,point_depart,ensemble_lignes, vertex_connus, vertex_impasse, graph_filaire_vertex)\n",
    "trajets.calculs_trajets()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_arret=bati_ligne_proche.ID.tolist().index(resultat.tail(1).bati.values[0])+1\n",
    "index_bati_erreur=bati_ligne_proche.ID.tolist()[index_arret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15527"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_arret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BATIMENT0000000257802004'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_bati_erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE RESULTATS FINAUX\n",
    "resultat.to_json(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\resultats_3.json')\n",
    "\n",
    "dico_save2={k:v.to_dict() for k, v in dico_df_tt_trajet.items()}\n",
    "f=open(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\df_tt_trajet_resultats_3.json','w')\n",
    "f.write(json.dumps(dico_save2))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
