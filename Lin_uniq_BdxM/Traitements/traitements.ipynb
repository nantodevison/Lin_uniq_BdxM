{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LINEARISATION UNIQUE DES TRAFICS SUR BORDEAUX METROPOLE**\n",
    "> ATTENTION : IL Y A DES MELI-MELO ENTRE LE FICHIER gdf_rhv_groupe qui contient un idtronc pour tout les troncons et a été constitué avant de prendre en compte les cat_rhv 62, 63 etc...; qui est utilisé dans toute la partie affectation points de comptage, et le fichier issus de la Bdd graph_filaire qui lui contient bien toute les lignes mais n'a pas d'idtronc renseigné.<br> il faudrait remettre tout ça à plat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys #c'est pas propre mais pour le moment pour importer mes modules perso dans le notebook je ne sais pas faire\n",
    "sys.path.append(r'C:\\Users\\marti\\git\\Outils\\Outils\\Martin_Perso')\n",
    "sys.path.append(r'C:\\Users\\marti\\git\\otv\\otv\\Transfert_Donnees')\n",
    "sys.path.append(r'C:\\Users\\marti\\git\\Lin_uniq_BdxM\\Lin_uniq_BdxM\\Traitements')\n",
    "import Connexion_Transfert as ct\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import MultiPoint, Polygon, box\n",
    "from shapely.ops import nearest_points\n",
    "from shapely.wkt import dumps, loads\n",
    "import re, json\n",
    "from copy import copy, deepcopy\n",
    "from difflib import get_close_matches,SequenceMatcher\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from Outils import creer_graph, plus_proche_voisin,nb_noeud_unique_troncon_continu,verif_index, gp_changer_nom_geom\n",
    "\n",
    "from Simplifier_Rdpt import creer_dico_noeud_rdpt,simplifier_noeud_rdpt,maj_graph_rdpt, donnees_tot_rd_pt\n",
    "import Estim_trafic as et\n",
    "import Comptage as Cpt\n",
    "import Affectation_pt_comptage as ap\n",
    "import Voies_Cat4 as v4\n",
    "from MMM import import_fichiers_mmm\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "\n",
    "from Base_BdTopo.Import_outils import import_donnes_base\n",
    "from Base_BdTopo.Rond_points import identifier_rd_pt\n",
    "from Base_BdTopo.Regroupement_correspondance import *\n",
    "from Base_BdTopo.Troncon_elementaire import *\n",
    "from Base_BdTopo.Troncon_base import *\n",
    "from Base_BdTopo.Gestion_2_chaussee import *\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Regrouper les troncons du filaire de voie\n",
    ">Les troncons du filaire de voie sont regroupés d'abord uniquement avec les troncons de cat_rhv égal à 1,2,3,61,62,63, pour pouvoir réaliser des troncon de trafic homogènes tous reliés entre eux.\n",
    "<br> Ensuite, un deuxième regroupement comprenant l'ensemble des troncons de cat_rhv permetd'affiner le diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 1.1 Import du fichier final\n",
    "le fichier shape est vérifié à la main car l'affectation automatique n'est pas 100% fiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour info : lire le graph issu de la methode decrite dessous\n",
    "with ct.ConnexionBdd('local_otv') as c :\n",
    "    graph_filaire_123 = gp.read_postgis('select * from linearisation_bm.graph_rhv_123_v2', c.connexionPsy)\n",
    "    graph_filaire_123_vertex = gp.read_postgis('select id,cnt,chk,ein,eout,the_geom as geom from linearisation_bm.graph_rhv_123_v2_vertices_pgr', c.connexionPsy)\n",
    "    graph_filaire = gp.read_postgis('select * from linearisation_bm.graph_rhv_complet', c.connexionPsy)\n",
    "    graph_filaire_vertex=gp.read_postgis('select id,cnt,chk,ein,eout,the_geom as geom from linearisation_bm.graph_rhv_complet_vertices_pgr', c.connexionPsy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_rhv_groupe_123=graph_filaire_123\n",
    "\"\"\"gdf_rhv_groupe_123=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_groupe_123_v2.shp').merge(\n",
    "    graph_filaire_123[['ident','source','target']], on='ident', how='left')\"\"\"\n",
    "gdf_rhv_groupe=gp.read_file(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\rhv_grp.shp').merge(\n",
    "    graph_filaire[['ident','source','target']], on='ident', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 1.2 Méthode\n",
    " pour information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. import du fichier de filaire de base\n",
    "gdf_rhv=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\Bdx-Metro\\Filaire_voie\\FV_TRONC_L.shp')\n",
    "# 2. mise en forme\n",
    "gdf_rhv.columns=[a.lower() for a in gdf_rhv.columns] #nom de colonne en minuscule\n",
    "gdf_rhv.rename(columns={'gid':'id','nom_voie' : 'numero'},inplace=True)\n",
    "gdf_rhv=gdf_rhv.loc[~gdf_rhv.id.isna()].copy()\n",
    "gdf_rhv['id_ign']=gdf_rhv.ident.apply(lambda x : 'TRONROUT'+str(x))\n",
    "gdf_rhv=gdf_rhv.loc[~gdf_rhv.cat_rhv.isin(['98','99'])].copy()\n",
    "gdf_rhv['nature']=gdf_rhv.apply(lambda x : 'Route à 2 chaussées' if x['rgraph_dbl']==0 else 'Route à 1 chaussée', axis=1)\n",
    "gdf_rhv['nature']=gdf_rhv.apply(lambda x : 'Bretelle' if x['cat_dig']=='8' else x['nature'], axis=1)\n",
    "gdf_rhv['numero']=gdf_rhv.apply(lambda x : 'Bretelle '+x['numero'] if x['cat_dig']=='8' else x['numero'], axis=1)\n",
    "gdf_rhv['sens']=gdf_rhv.apply(lambda x : 'Direct' if x['rgraph_dbl']==0 else 'Double', axis=1)\n",
    "gdf_rhv['codevoie_d']='NR'\n",
    "gdf_rhv['importance']=gdf_rhv['cat_dig']\n",
    "gdf_rhv['id']=gdf_rhv.id.apply(lambda x : int(x))\n",
    "#gdf_rhv.loc[gdf_rhv.nom_voie.isna()] #verif des nom_voie null : 2 lignes, cf traitements plus loins\n",
    "#filtrer les voies cylcables et autres\n",
    "gdf_rhv_filtre=gdf_rhv.loc[~gdf_rhv.cat_dig.isin(['6','7','9','10'])].copy()\n",
    "\n",
    "# 3. creer le graph en bdd\n",
    "#creer_graph(gdf_rhv_filtre.loc[gdf_rhv_filtre.cat_rhv.isin(['1','2','3','33','61','62','63'])],\n",
    "            #'local_otv',schema='linearisation_bm',table='graph_rhv_123',table_vertex='graph_rhv_123_vertices_pgr')\n",
    "creer_graph(gdf_rhv_filtre,'local_otv',schema='linearisation_bm',table='graph_rhv_complet',table_vertex='graph_rhv_complet_vertices_pgr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 4. initialiser les paramètre de regroupement\n",
    "df=import_donnes_base('local_otv','linearisation_bm', 'graph_rhv_complet','graph_rhv_complet_vertices_pgr')\n",
    "df2_chaussees=df.loc[df.nature.isin(['Autoroute', 'Quasi-autoroute', 'Route à 2 chaussées'])]\n",
    "df_avec_rd_pt,carac_rd_pt,lign_entrant_rdpt=identifier_rd_pt(df)\n",
    "df_lignes=df_avec_rd_pt.set_index('id_ign')#mettre l'id_ign en index\n",
    "bretelle=df_avec_rd_pt.loc[df_avec_rd_pt['nature']=='Bretelle'].copy()\n",
    "bretelle_tri=bretelle.loc[bretelle.length.sort_values(ascending=False).index.tolist()].id_ign.tolist()\n",
    "sans_bretelle=df_avec_rd_pt.loc[df_avec_rd_pt['nature']!='Bretelle'].copy()\n",
    "list_sans_bretelle=sans_bretelle.id_ign.tolist()\n",
    "list_tri_longueur=sans_bretelle.loc[sans_bretelle.length.sort_values(ascending=False).index.tolist()].id_ign.tolist()\n",
    "list_id_ign=bretelle_tri+list_tri_longueur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 5. appel fonction de grouepement pour creer des idtronc pour uniquement voies de 1 à 3 et d'un autre coté pour toute les voies\n",
    "df_affectation, dico_erreur, lignes_traitees, lignes_non_traitees=regrouper_troncon(\n",
    "    list_id_ign, df_avec_rd_pt, carac_rd_pt,df2_chaussees,[])\n",
    "\n",
    "# 6. mise en forme et export\n",
    "gdf_rhv_groupe=gdf_rhv_filtre.merge(df_affectation, left_on='id_ign', right_on='id', how='left')\n",
    "gdf_rhv_groupe.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\rhv_grp_v2.shp')\n",
    "#gdf_rhv_groupe_123=gdf_rhv_filtre.merge(df_affectation, left_on='id_ign', right_on='id', how='left')\n",
    "#gdf_rhv_groupe_123.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_groupe_123.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MISE EN FORME DES COMPTAGES PONCTUELS\n",
    "Pour ces comptages l'idée c'est de réussir à regrouper les comptages par un idtronc issu de la detection des troncon elementaire. ça a du sens car pour un comptage ponctuel normalement les 2 sens de cicru sont sur un troncon unique. DE plus, les ens circu, noms de voie et autres attributs permettant de regrouper les comptages sont de qualité trop variable pour s'appuyer uniquement dessus. et enfin, peu de 2*2 vois sont meusrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "affect_finale,cpt_pct_l93=Cpt.traitements_bdxm_pct(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\Bdx-Metro\\comptages\\base_comptages_routiers_finale.xlsx',gdf_rhv_groupe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MISE EN FORME DES COMPTAGES PERMANENTS\n",
    "Pour ces compteurs on va regrouper en séparant les siredo des boucles liées au système gertrude. Pour les siredo pas de pb, pour les autre sc'est plus compliqué car les références de localiusation varient parfois. Il y a donc une phase de regroupement manuel à la fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 2.1 Import du fichier final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import fichier corrige_final\n",
    "cpt_perm_final=gp.read_file(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\cpt_perm_groupe.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 2.1 Méthode\n",
    "Pour info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#creer un gdf avec la fusion des points et des données de comptages non nulles\n",
    "cpt_brut=pd.read_excel(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\Bdx-Metro\\comptages\\comptage_trafic_final.xls')\n",
    "cpt_brut.columns=[a.lower() for a in cpt_brut.columns]\n",
    "cpt_brut=cpt_brut.loc[~cpt_brut.mjo_val.isna()].copy()\n",
    "pt_cpt_perm=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\Bdx-Metro\\comptages\\PC_CAPTE_P.shp')\n",
    "pt_cpt_perm.columns=[a.lower() for a in pt_cpt_perm.columns]\n",
    "pt_cpt_perm=pt_cpt_perm.merge(cpt_brut, on='ident')\n",
    "pt_cpt_perm['nom_voie']=pt_cpt_perm.nom_voie.apply(lambda x : re.sub(('é|è|ê'),'e',x.lower().replace('  ',' ')))#mise en forme nom de voie\n",
    "\n",
    "#regrouper les comptages\n",
    "#un compteur peut caracteriser 1 ligne, ou 2 compteur 1 ligne ou 2 compteurs 2 lignes, dc les compteurs ne vont pas toujours par deux\n",
    "\n",
    "#regrouper geographiquement\n",
    "pt_cpt_perm['x_l93']=pt_cpt_perm.geometry.apply(lambda x : x.x)\n",
    "pt_cpt_perm['y_l93']=pt_cpt_perm.geometry.apply(lambda x : x.y)\n",
    "data_test_clust=[[x, y] for x, y in zip(pt_cpt_perm.x_l93.tolist(), pt_cpt_perm.y_l93.tolist())]\n",
    "db = DBSCAN(eps=200, min_samples=2).fit(data_test_clust)\n",
    "labels = db.labels_\n",
    "pt_cpt_perm['n_cluster']=labels\n",
    "\n",
    "#correspondance nom_rue\n",
    "#analyser les noms de commune : \n",
    "#grp_nom_voie.nom_voie.apply(lambda x : x.split()[0]).unique()#liste des permiers mots\n",
    "#grp_nom_voie.loc[grp_nom_voie.nom_voie.apply(lambda x : x.split()[0]=='carbon')].nom_voie.unique() #test des valeusr\n",
    "dico_commune={'le bouscat','le haillan','bordeaux','pessac','talence', 'merignac','st medard','carbon blanc',\n",
    "       'begles', 'eysines','villenave d\\'ornon','bruges','gradignan','bassens','cenon','floirac','pessa','lormont', 'artigues'}\n",
    "dico_type_voie={'allee' : ['all.','allee', 'allees'],'avenue': ['av', 'av.', 'avenue'], 'boulevard' : ['blvd'],\n",
    "               'bretelle' : 'bretelle', 'cours' : ['crs','cours'], 'cote' : ['côte'], 'place':['pl'], 'route':['route', 'rte'],'rue':['rue'],\n",
    "               'voie':['voie']}\n",
    "def decoupe_nom_voie(nom_voie) : \n",
    "    for c in dico_commune : \n",
    "        if nom_voie[:len(c)]==c :\n",
    "            commune=nom_voie[:len(c)]\n",
    "            nom_voie=nom_voie[len(c):].strip()\n",
    "    for k, v in dico_type_voie.items() : \n",
    "        if any([a for a in nom_voie.split() if a in v])  : \n",
    "            caractere=[a for a in nom_voie.split() if a in v][0]\n",
    "            type_voie=k\n",
    "            nom_voie=' '.join([n for n in nom_voie.split() if n!=caractere])\n",
    "            break\n",
    "    else : type_voie=None\n",
    "    for test in ['avant','apres'] :\n",
    "        if test in nom_voie : \n",
    "            return nom_voie.split(test)[0].strip(), test,nom_voie.split(test)[1].strip(), commune, type_voie\n",
    "    else : return nom_voie, nom_voie,nom_voie,commune,type_voie\n",
    "\n",
    "pt_cpt_perm['nom_rue']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[0])\n",
    "pt_cpt_perm['localisant']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[1])\n",
    "pt_cpt_perm['rue_refer']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[2])\n",
    "pt_cpt_perm['commune']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[3])\n",
    "pt_cpt_perm['type_voie']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[4])\n",
    "pt_cpt_perm.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\pt_cpt_perm.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>#### 2.2.1 SIREDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "siredo=pt_cpt_perm.loc[pt_cpt_perm['type']=='SIREDO'].copy()#isoler siredo\n",
    "cross_join=siredo.assign(key=1).merge(siredo.assign(key=1), on='key').drop('key',axis=1)#calcul des distances\n",
    "cross_join['distance']=cross_join.apply(lambda x : x['geometry_x'].distance(x['geometry_y']),axis=1)\n",
    "cross_join_filtre=cross_join[[c for c in cross_join.columns if c[-2:]=='_x']+['distance','ident_y']].rename(columns=\n",
    "              {c : c[:-2] for c in cross_join.columns if c[-2:]=='_x'}).copy()#filtre des attribut\n",
    "cross_join_filtre=cross_join_filtre.loc[(cross_join_filtre['ident']!=cross_join_filtre['ident_y'])].copy()\n",
    "siredo_proches=cross_join_filtre.loc[(cross_join_filtre.groupby('ident')['distance'].transform(min)==\n",
    "                                      cross_join_filtre['distance'])].copy()#plus proche voisin\n",
    "siredo_proches['id_grpsiredo']=siredo_proches.reset_index().index\n",
    "id_siredo_proches=(pd.concat([siredo_proches[['ident','ident_y', 'id_grpsiredo']],\n",
    "           siredo_proches[['ident_y','ident', 'id_grpsiredo']].rename(columns={\n",
    "    'ident_y':'ident', 'ident':'ident_y'})],sort=False).sort_values('ident').\n",
    "    reset_index().drop_duplicates('index').drop_duplicates(['ident','ident_y']).drop('index',axis=1))\n",
    "cle_assoc_siredo=pd.concat([id_siredo_proches[['ident','id_grpsiredo']],id_siredo_proches[['ident_y','id_grpsiredo']].rename(columns={\n",
    "    'ident_y':'ident'})]).sort_values('id_grpsiredo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>#### 2.2.2 Gertrude\n",
    "> au final ce n'est pas très efficace, et un renseignement des regroupement a la ain aurait été plus rapide. il sera important si de nouvelles stations sont posées de fournir de suite un identifiant de regroupement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gertrude=pt_cpt_perm.loc[pt_cpt_perm['type']=='BOUCLE'].copy()#isoler les boucles\n",
    "gertrude['x']=gertrude.geometry.apply(lambda x : x.x)\n",
    "gertrude['y']=gertrude.geometry.apply(lambda x : x.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#si c'est sur le mm idtronc on regroupe\n",
    "\n",
    "#rappatrier le numero d'id_tronc pour chaque comptage\n",
    "#trouver la distance min à chaque objet ligne\"du rhv groupe\n",
    "grp_troncon_temp=gertrude.copy()\n",
    "grp_troncon_temp.geometry=grp_troncon_temp.buffer(20)#passer la geom en buffer\n",
    "intersct_buff_20=gp.sjoin(grp_troncon_temp,gdf_rhv_groupe,how='left',op='intersects')\n",
    "intersct_buff_20.geometry=gertrude.geometry#repasser la geom en point\n",
    "intersct_buff_20=intersct_buff_20.merge(gdf_rhv_groupe[['ident','geometry']], left_on='ident_right', right_on='ident')\n",
    "intersct_buff_20['dist_pt_ligne']=intersct_buff_20.apply(lambda x : x['geometry_x'].distance(x['geometry_y']), axis=1) #définir la disance entre les points et ligne\n",
    "joint_dist_min=intersct_buff_20.loc[intersct_buff_20.groupby('ident_left')['dist_pt_ligne'].transform(min)==intersct_buff_20['dist_pt_ligne']][['ident_left','idtronc','numero']].rename(\n",
    "    columns={'ident_left':'ident'}).copy()#ne garder que la ligne la plus proche\n",
    "grp_troncon=gertrude.merge(joint_dist_min, on='ident',how='left')#df finale\n",
    "\n",
    "#regrouper\n",
    "grp_idtronc=grp_troncon.groupby('idtronc')['ident'].agg(lambda x : tuple(x))\n",
    "grp_idtronc=grp_idtronc.loc[grp_idtronc.apply(lambda x : len(x)>1)].reset_index().copy()\n",
    "grp_idtronc['id_grp']=grp_idtronc.ident.rank()\n",
    "#mettre en forme\n",
    "grp_idtronc=pd.DataFrame([(a,g) for i,g in zip(grp_idtronc.ident.tolist(),grp_idtronc.id_grp.tolist()) for a in i], columns=['ident','id_grp'])\n",
    "grp_final=grp_idtronc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# trouver les points qui restent et préparer un regrouepement par commune, nom de rue, distance et se,s\n",
    "\n",
    "#points qui restent\n",
    "gertrude_etape2=gertrude.loc[~gertrude['ident'].isin(grp_idtronc.ident.tolist())].copy()\n",
    "#comparer les noms\n",
    "cross_join=gertrude_etape2[['gid','geometry','ident','nom_voie', 'sens_cir','commune', 'nom_rue', 'localisant','rue_refer','type_voie']].assign(key=1).merge(\n",
    "    gertrude_etape2[['gid','geometry','ident','nom_voie', 'sens_cir','commune', 'nom_rue', 'localisant','rue_refer','type_voie']].assign(key=1), on='key').drop('key',axis=1)#calcul des distances\n",
    "cross_join['distance']=cross_join.apply(lambda x : x['geometry_x'].distance(x['geometry_y']),axis=1)\n",
    "cross_join['comp_nom_rue']=cross_join.apply(lambda x : SequenceMatcher(None,x['nom_rue_x'], x['nom_rue_y']).ratio(), axis=1)#affecter une note a cahque relation\n",
    "\n",
    "#vérifier que les sens de cicru sont cohérents et ne garder que les lignes avec un sens ok, un nom de voie proche et une distance proche\n",
    "gertrude_join=cross_join.loc[(cross_join['comp_nom_rue']>0.6) & (cross_join['distance']<1000) & (cross_join['commune_x']==cross_join['commune_y']) & \n",
    "                             (cross_join['type_voie_x']==cross_join['type_voie_y'])].copy()\n",
    "#on ajoute un attribut de verif du sens\n",
    "def verif_sens(s1,s2) : \n",
    "    for sens in [['Sens Sortant', 'Sens Entrant'],['Sens N > S', 'Sens S > N'], ['Sens Nord > Sud', 'Sens Sud > Nord'],['Nord > Sud', 'Sud > Nord'],\n",
    "                ['Boulevards Nord > Sud', 'Boulevards Sud > Nord']] :\n",
    "        if s1 in sens and s2 in sens : \n",
    "            if s1!=s2 : \n",
    "                return True\n",
    "        else : \n",
    "            continue\n",
    "    return False\n",
    "gertrude_join['valid_sens']=gertrude_join.apply(lambda x : verif_sens(x['sens_cir_x'],x['sens_cir_y']),axis=1)  \n",
    "gertrude_join['id_grp']=gertrude_join.sort_values('ident_x').ident_x.rank(method=\"min\")\n",
    "gertrude_grp=gertrude_join.loc[gertrude_join['valid_sens']][['ident_x','ident_y','distance', 'comp_nom_rue', 'valid_sens','id_grp']].sort_values('ident_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#obtenir une liste des ident qui se regroupent\n",
    "list_id_grp=pd.concat([gertrude_grp[['ident_x','id_grp']],gertrude_grp[['ident_y','id_grp']].rename(columns={'ident_y' : 'ident_x'})]).drop_duplicates([\n",
    "    'ident_x','id_grp']).groupby('id_grp').ident_x.agg(lambda x : set(sorted(tuple(x)))).tolist()\n",
    "dico={}\n",
    "for e,c in enumerate(gertrude_grp.ident_x.tolist()) : \n",
    "    for l in list_id_grp : \n",
    "        if c in l :\n",
    "            #print('c dans l','c : ',c,'l :',l)\n",
    "            if c not in dico.keys() :\n",
    "                dico[c]=list(l)\n",
    "            else : \n",
    "                dico[c]+=list(l)\n",
    "list_id_grp_temp=set([ v for v in {k : tuple(set(sorted(dico[k]))) for k in dico.keys()}.values()])\n",
    "list_id_grp_final=set(v for v in {c :b for c in gertrude_grp.ident_x.tolist() \n",
    " for b in [a for a in list_id_grp_temp if c in a] \n",
    " if len(b) == max([len(c) for c in [a for a in list_id_grp_temp if c in a]])}.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#affecter un identifiant\n",
    "def groupe_pt_gertrude_etape2(df_local) : \n",
    "    \"\"\"\n",
    "    regrouper les points à partir d'une liste d'ident selon l'ordre d'apparition \n",
    "    \"\"\"\n",
    "    limite_box=MultiPoint([(a.x,a.y) for a in df_local.itertuples()]).bounds\n",
    "    plg_long, plg_larg=limite_box[2]-limite_box[0],limite_box[3]-limite_box[1]\n",
    "    if max(plg_long,plg_larg)==plg_long : \n",
    "        df_local['next_sens']=df_local.sort_values('x').sens_cir.shift(-1,fill_value='NC')\n",
    "        df_local['prev_sens']=df_local.sort_values('x').sens_cir.shift(1,fill_value='NC')\n",
    "    else : \n",
    "        df_local['next_sens']=df_local.sort_values('y').sens_cir.shift(-1,fill_value='NC')\n",
    "        df_local['prev_sens']=df_local.sort_values('y').sens_cir.shift(1,fill_value='NC')\n",
    "    df_local['sens_comp']=df_local.apply(lambda x : x.prev_sens if x.next_sens=='NC' else x.next_sens,axis=1)\n",
    "    df_local['verif_sens']=df_local.apply(lambda x : verif_sens(x['sens_cir'],x['sens_comp']),axis=1)\n",
    "    df_local['id_grp']=-99\n",
    "    i=0\n",
    "    while i < len(df_local)-1:\n",
    "        if df_local.iloc[i].verif_sens : \n",
    "            df_local.loc[df_local.index.isin(df_local.iloc[i:i+2].index.tolist()),'id_grp']=i\n",
    "            i+=2\n",
    "        else : \n",
    "            i+=1\n",
    "    return\n",
    "\n",
    "# à partior de la liste des ident groupé : \n",
    "grp_final2=grp_final.copy()\n",
    "# on selectionne ces points dans la df\n",
    "increment=grp_final2.id_grp.max()\n",
    "for l in list_id_grp_final : \n",
    "    #if 'Z8CT13' not in l : continue\n",
    "    df_local=gertrude_etape2.loc[gertrude_etape2.ident.isin(l)].copy()\n",
    "    if len(df_local)==1:\n",
    "        continue\n",
    "    if len(df_local)==2 : \n",
    "        if (gertrude_join.loc[(gertrude_join.ident_x.isin(l)) & (gertrude_join['ident_x'] != gertrude_join['ident_y'])].valid_sens).all() : \n",
    "            increment+=1\n",
    "            df_local['id_grp']=increment\n",
    "            grp_final2=pd.concat([grp_final2,df_local[['ident','id_grp']]],sort=False)\n",
    "    else :\n",
    "        groupe_pt_gertrude_etape2(df_local)\n",
    "        increment+=grp_final2.id_grp.max()\n",
    "        df_local.loc[df_local['id_grp']!=-99,'id_grp']=df_local['id_grp']+increment\n",
    "        grp_final2=pd.concat([df_local[['ident','id_grp']],grp_final2],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#rappatrier l'id_grp sur les données de base et export pour modif manuelle\n",
    "gertrude.merge(grp_final2, on='ident',how='left').to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gertrude.shp')\n",
    "\n",
    "#import des modifs manuelles et mise en forme finale\n",
    "gertrude_manu=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gertrude.shp')\n",
    "gertrude_manu.loc[(gertrude_manu.id_grp.isna()) | (gertrude_manu.id_grp==-99),'id_grp']=gertrude_manu.loc[(gertrude_manu.id_grp.isna()) | (gertrude_manu.id_grp==-99),'id_grp'].reset_index().index + gertrude_manu.id_grp.max()\n",
    "gertrude_manu.loc[gertrude_manu.type_grp.isnull(),'type_grp']='auto'\n",
    "#export pour dernière modif manuelle\n",
    "gertrude_manu.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gertrude_final.shp')\n",
    "\n",
    "#fichier final\n",
    "gertrude_fin=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gertrude_final.shp')\n",
    "#concat avec les siredo\n",
    "cle_assoc_siredo['id_grpsiredo']=cle_assoc_siredo['id_grpsiredo']+gertrude_fin.id_grp.max()\n",
    "cpt_perm_final=pd.concat([gertrude_fin,siredo.merge(cle_assoc_siredo, on='ident').rename(columns={'id_grpsiredo':'id_grp'})],axis=0, sort=False)\n",
    "cpt_perm_final.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\cpt_perm_groupe.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Affecter du trafic au filaire de voie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### On commence par affecter le trafic aux troncons des catégories 1,2,3 à partirdes comptages permanents.<br> Pour le détail des fonctions cf module Affectation_pt_comptage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_rhv_cpt_perm_123,lgn_proche_perm=ap.affectation_cpt_perm(cpt_perm_final,gdf_rhv_groupe,gdf_rhv_groupe_123,10)\n",
    "#ap.export_cpt_perm_linearises(gdf_rhv_cpt_perm_123,r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_123_cpt_perm.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ensuite les comptages ponctuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#affectation des comptages ponctuels et exports\n",
    "gdf_traf_tot=ap.affectation_cpt_ponct(cpt_pct_l93, affect_finale, lgn_proche_perm, gdf_rhv_groupe, 10, gdf_rhv_groupe_123, gdf_rhv_cpt_perm_123)\n",
    "#ap.export_cpt_ponct_linearises(gdf_traf_tot,r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_123_cpt_perm-ponct.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MMM\n",
    "En premier lieu il faut mettre à jour les attributs en renomant de façon explicite puis en faisant la somme des 2 sens de circulation pour les voies doucble sens cf module MMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fichier_src_simpl=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\MMM\\MMM_Maj_EDA2017\\simplifie\\MMM_simple_2019.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#creer graph et importer \n",
    "creer_graph(fichier_src_simpl, 'local_otv',id_name='NO', schema='linearisation_bm', table='mmm_graph_2019', table_vertex='mmm_graph_2019_vertices_pgr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#importer le graph\n",
    "with ct.ConnexionBdd('local_otv') as c :\n",
    "    graph_mmm_filaire = gp.read_postgis('select * from linearisation_bm.mmm_graph_2019', c.connexionPsy)\n",
    "    graph_mmm_filaire_vertex = gp.read_postgis('select * from linearisation_bm.mmm_graph_2019_vertices_pgr', c.connexionPsy,geom_col='the_geom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer les fichiers finaux\n",
    "mmm_simple,cle_mmm_rhv=import_fichiers_mmm(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\MMM\\MMM_Maj_EDA2017\\simplifie\\MMM_simple_2019.shp',\n",
    "                                            r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\appariementV0.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affecter du trafic aux voies non connues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHODE A UTILISER\n",
    "gdf_base=gdf_traf_tot.copy()\n",
    "lgn_rdpt, dico_noeud, gdf_rhv_rdpt_simple=donnees_tot_rd_pt(gdf_base, 'local_otv','linearisation_bm', 'graph_rhv_123_v2','graph_rhv_123_v2_vertices_pgr')\n",
    "gdf_rhv_rdpt_simple5=gdf_rhv_rdpt_simple.copy()\n",
    "\n",
    "et.calculer_trafic_3voies(gdf_base,gdf_rhv_rdpt_simple5,lgn_rdpt,graph_filaire_123_vertex)\n",
    "\n",
    "gdf_calcul=gdf_base.copy()\n",
    "gdf_rhv_rdpt_simple2=gdf_rhv_rdpt_simple5.copy()\n",
    "et.calculer_trafic_mmm(gdf_calcul, gdf_rhv_rdpt_simple2,lgn_rdpt,graph_filaire_123_vertex,mmm_simple,cle_mmm_rhv,dico_noeud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#EXPORT RESULTATS\n",
    "gdf_calcul['id_cpt_exp']=gdf_calcul['id_cpt_2_sens'].fillna('NC')\n",
    "gdf_calcul['id_cpt_exp']=gdf_calcul.apply(lambda x : ', '.join([str(a) for a in x['id_cpt_exp']]) \n",
    "                if isinstance(x['id_cpt_2_sens'],tuple) else str(x['id_cpt_2_sens']), axis=1)\n",
    "gdf_calcul.reset_index()[['id', 'ident', 'domanial', 'groupe', 'cat_dig', 'cat_rhv', 'passage',\n",
    "       'rggraph_nd', 'rggraph_na', 'rgraph_dbl', 'numero', 'cdate', 'mdate',\n",
    "       'id_ign', 'nature', 'sens', 'codevoie_d', 'importance', 'id_y','source', 'target',\n",
    "       'idtronc', 'geom','tmjo_2_sens','type_cpt', 'id_cpt_exp']].to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_123_calcul_mmm_v6.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# POUR TEST SUR UN NOEUD UNIQUEMNET METHODE 3 VOIES\n",
    "gdf_base2=gdf_traf_tot.copy()\n",
    "gdf_rhv_rdpt_simple3=gdf_rhv_rdpt_simple.copy()\n",
    "#remplacement des sources et targets : \n",
    "simplifier_noeud_rdpt(gdf_rhv_rdpt_simple3, dico_noeud)\n",
    "#puis recalculer le count du nb de ligne par noeud (en otant les lignes qui font les rdpoints)\n",
    "df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple3)[2:4]\n",
    "liste_noeud_traite=[]\n",
    "liste_noeud_mmm=[]\n",
    "dico_erreur={}\n",
    "num_noeud=2082\n",
    "gdf_rhv_rdpt_simple3=verif_index(gdf_rhv_rdpt_simple3,'idtronc')#Îsi idtronc est en index on le repasse dans les colonnes\n",
    "\n",
    "df_troncon_noeud=et.carac_troncon_noeud(gdf_rhv_rdpt_simple3, gdf_base2, graph_filaire_123_vertex,num_noeud,df_noeuds,lgn_rdpt)\n",
    "  #si tous les trafics du noeud sont déjà renseignés on passe\n",
    "  #determiner si on est dans le cas d'une voie pouvant etre estimée par calcul (3 troncon dont 1 seul manquant) ou par analogie avec le MMM\n",
    "et.maj_trafic_3tronc(df_troncon_noeud)\n",
    "df_update_traf=df_troncon_noeud[['idtronc','tmjo_2_sens','type_cpt']].set_index('idtronc').drop_duplicates()\n",
    "df_update_traf.update(pd.DataFrame.from_records(dico_corection_calcul_3_voies, columns=['idtronc','tmjo_2_sens', 'type_cpt']).set_index('idtronc').fillna('NC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#TEST APPARtENANCE A UN ROND POINT\n",
    "for a in [9314,6404,6403, 8206, 9315] : \n",
    "    if a in df_noeuds.noeud.tolist() : \n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# POUR TEST SUR UN NOEUD UNIQUEMNET METHODE MMM\n",
    "gdf_test=gdf_base.copy()\n",
    "df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple5)[2:4]\n",
    "num_noeud=1002\n",
    "dico_erreur={}\n",
    "df_troncon_noeud=et.carac_troncon_noeud(gdf_rhv_rdpt_simple5, gdf_test, graph_filaire_123_vertex,num_noeud,df_noeuds,lgn_rdpt)\n",
    "dico_troncons_noeud=et.creer_dico_troncons_noeud(df_troncon_noeud,gdf_rhv_rdpt_simple5,gdf_base,lgn_rdpt,graph_filaire_123_vertex )\n",
    "matrice_rhv=et.matrice_troncon_noeud_rhv(df_troncon_noeud,num_noeud,lgn_rdpt,dico_troncons_noeud) \n",
    "try :\n",
    "    joint_fv_mmm_e2=et.estim_mmm_jointure_voies(matrice_rhv,cle_mmm_rhv)\n",
    "except et.PasCorrespondanceError : \n",
    "    dico_erreur[num_noeud]='PasCorrespondanceError'\n",
    "    df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple5)[2:4]\n",
    "    liste_noeud_estim=[n for n in liste_noeud_estim if n not in liste_noeud_traite]\n",
    "try :\n",
    "    trafic_inconnus_prior_cat=et.isoler_trafic_inconnu(joint_fv_mmm_e2)\n",
    "except et.PasDeTraficInconnuError: \n",
    "    dico_erreur[num_noeud]='PasDeTraficInconnuError' \n",
    "    df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple5)[2:4]\n",
    "    liste_noeud_estim=[n for n in liste_noeud_estim if n not in liste_noeud_traite]\n",
    "try :\n",
    "    trafc_rens=et.trafic_mmm(gdf_test,trafic_inconnus_prior_cat,mmm_simple,cle_mmm_rhv, df_troncon_noeud,dico_troncons_noeud,lgn_rdpt,dico_noeud,num_noeud)\n",
    "    df_update_traf=et.calcul_trafic_rhv_depuisMMM(trafc_rens).set_index('idtronc').rename(columns={'tmjo_2_sens_extrapol':'tmjo_2_sens'})\n",
    "except et.PasDeTraficError as e: \n",
    "    dico_erreur[num_noeud]=e \n",
    "    df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple5)[2:4]\n",
    "    liste_noeud_estim=[n for n in liste_noeud_estim if n not in liste_noeud_traite]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voies catégorie 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affectation comptages ponctuels\n",
    "> Normalement les comptages ponctuels sont deja assignes aux idtronc relatifs au troncon elementaires toutes catégories. Il faut donc isoler les voies non contenues dans le regrouepement des cat 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rhv_grp_hors_123,affect_finale_cat4,cpt_perm_cat4=v4.isolerDonneesCat4(gdf_rhv_groupe,gdf_rhv_groupe_123, affect_finale,lgn_proche_perm)\n",
    "groupe_ident_cpt,cpt_cat4_uniq_sens_dbl,cat4_lgn_pb=v4.jointureTraficLigne(rhv_grp_hors_123,affect_finale_cat4,cpt_perm_cat4)\n",
    "rhv_grp_hors_123_traf=v4.calculTraficPointComptage(rhv_grp_hors_123,groupe_ident_cpt,cpt_cat4_uniq_sens_dbl,cat4_lgn_pb,[3094, 4687, 8724, 10025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#fichier avec cat1,2,3 et comptage sur cat4\n",
    "gdf_traf_1234=pd.concat([rhv_grp_hors_123_traf.loc[~rhv_grp_hors_123_traf.tmjo_2_sens.isna()],gdf_calcul], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gdf_traf_1234.reset_index()[['id', 'ident', 'domanial', 'groupe', 'cat_dig', 'cat_rhv', 'passage',\n",
    "       'rggraph_nd', 'rggraph_na', 'rgraph_dbl', 'numero', 'cdate', 'mdate',\n",
    "       'id_ign', 'nature', 'sens', 'codevoie_d', 'importance', 'id_y','source', 'target',\n",
    "       'idtronc', 'geom','tmjo_2_sens','type_cpt', 'id_cpt_exp']].to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_1234_cpt.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affectation auto à partir du bati \n",
    "> L'idée c'est d'affecter un tmja a chaque troncon elementaire à partir du nb d'habitantassocier à la ligne la plus proche, puis de moduler ça selon le nb de déplcament motorisée lies au domicile. si apres on arrive aussi a ajouter les tmja pour les voies non reliees aux reseau de cat 1,2,3 c'est parfait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des donnees\n",
    "gdf_traf_1234, voies_nc, bati,coreesp_bati2=v4.importDonneesBase(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_1234_cpt.shp',\n",
    "                                                                 r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\voie_non_affectees.shp',\n",
    "                                                                 r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\bati.shp',\n",
    "                                                                 r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\ppv_bati-route_V2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des trajets les plus courts vers une voie au trafic connu\n",
    "> test sur un seul batiment  : 'BATIMENT0000000256067979'.<br> on va alimenter des listes de parcours : list des vertex à tester, list des ident parcouru,list des vertex parcouru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Test : creation d'une classe ensemble de trajet**<br>\n",
    ">>doit permettre : \n",
    "* de verifier le statut de tous les trajets. method : verif_statut_trajets()\n",
    "* de calculer tous les trajets. method : calcul_trajets()\n",
    "* trouver les trajets non finis. method : trajets_en_cours()\n",
    "* creer des nouveaux trajets. method : creer_trajet()\n",
    "* trouver les lignes a ajouter aux trakets en cours. method : trouver_nouvelles_lignes()\n",
    "* ajouter une ligne à un trajet existant. method : ajouter_ligne.<br> \n",
    "\n",
    ">>Se base sur : \n",
    "* lignes depart\n",
    "* ensemble de lignes\n",
    "* vertex connus\n",
    "* vertex_impasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#recuperer les donnees necessaire a la recherche du trajet le plus rapide vers un point non connu\n",
    "bati_ligne_proche,ensemble_lignes,vertex_connus, vertex_impasse=v4.definitionVariables(graph_filaire,gdf_rhv_groupe,gdf_traf_1234, voies_nc, bati,coreesp_bati2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('24279', '14826', '51783', '51782')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#test sur une ligne\n",
    "#il peut y avoir des erreurs dans le rhv, comme par exemple l'ident 14844 qui ne touche pas le 24285\n",
    "ident_proche_bati=str(bati_ligne_proche.loc[bati_ligne_proche['ID']=='BATIMENT0000000257801129'].ident.to_numpy()[0])#risque si ident pas trouver d'IndexError\n",
    "point_depart=bati_ligne_proche.loc[bati_ligne_proche['ID']=='BATIMENT0000000257801129'].point_proche.values[0]\n",
    "trajets=v4.ensemble_trajet(ident_proche_bati,point_depart,ensemble_lignes, vertex_connus, vertex_impasse, graph_filaire_vertex)\n",
    "trajets.initialiser_trajets() \n",
    "trajets.allonger_trajet()\n",
    "trajets.creer_df_tt_trajet()\n",
    "trajets.filtrer_df_tt_trajet()\n",
    "trajets.trajet_court=tuple(trajets.df_trajet_cat3_grp_OD.loc[trajets.df_trajet_cat3_grp_OD.longueur_tot==trajets.df_trajet_cat3_grp_OD.longueur_tot.min()].lignes.to_numpy()[0])\n",
    "trajets.point_arrive=trajets.df_trajet_cat3_grp_OD.loc[trajets.df_trajet_cat3_grp_OD.longueur_tot==trajets.df_trajet_cat3_grp_OD.longueur_tot.min()].points.to_numpy()[0][-1]\n",
    "#RESULTATS (cf module et attributs)\n",
    "trajets.trajet_court\n",
    "#trajets.df_tt_trajet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#mise en oeuvre\n",
    "#resultat=r_tot.copy()\n",
    "resultat=pd.DataFrame({'bati':[], 'ident':[], 'noeud_proche':[],'trajet_court':[],'comm':[], 'noeud_cat3':[]})\n",
    "#dico_df_tt_trajet=d_tot\n",
    "dico_df_tt_trajet={}\n",
    "#i=r_tot.index.max()+1\n",
    "i=0\n",
    "liste_bati_erreur=[]\n",
    "for e,b in enumerate(bati_ligne_proche['ID'].tolist()) : \n",
    "    if e%100==0 and e!=0:\n",
    "        print(f'nb bati traite : {e}, {datetime.now()},{b}')\n",
    "    try : #recuperer l'ident pres du bati a traiter, si pas d'ident, on continue\n",
    "        ident_proche_bati=str(bati_ligne_proche.loc[bati_ligne_proche['ID']==b].ident.to_numpy()[0])#risque si ident pas trouver d'IndexError\n",
    "    except IndexError : \n",
    "        liste_bati_erreur.append(b)\n",
    "        continue\n",
    "    if ensemble_lignes.loc[ensemble_lignes['ident']==ident_proche_bati].empty : #si l'ident du rhv proche du bati n'est pas dans la liste, on indique et on continue\n",
    "        resultat.loc[i]=[b,ident_proche_bati,np.NaN,np.NaN,'pas ident proche dans voies nc',np.NaN]\n",
    "        i+=1\n",
    "        continue\n",
    "    point_depart=bati_ligne_proche.loc[bati_ligne_proche['ID']==b].point_proche.values[0]\n",
    "    trajets=v4.ensemble_trajet(ident_proche_bati,point_depart,ensemble_lignes, vertex_connus, vertex_impasse, graph_filaire_vertex)\n",
    "    noeud_proche=trajets.noeud_proche\n",
    "    if ident_proche_bati in resultat.ident.tolist() : #si la ligne a deja ete traite avec un autre batiment\n",
    "        df_find_existant=resultat.loc[(resultat['ident']==ident_proche_bati) & (resultat['noeud_proche']==noeud_proche)] # si le noeud le plus proche est le mm que celui dun bati precedent, on ne fait que recuperer les donnees calculees car on est dans le mm cas\n",
    "        if not df_find_existant.empty:\n",
    "            resultat.loc[i]=[b,ident_proche_bati,noeud_proche,df_find_existant.trajet_court.values[0], 'Deduction_trajet-ident connu_noeud_proche connu',df_find_existant.noeud_cat3.values[0]]\n",
    "            i+=1\n",
    "        else : #sinon on deroule le processus\n",
    "            trajets.df_trajet_cat3_grp_OD=dico_df_tt_trajet[ident_proche_bati]\n",
    "            trajets.maj_longueur_tot(trajets.df_trajet_cat3_grp_OD)\n",
    "            df_finale=trajets.df_trajet_cat3_grp_OD.loc[trajets.df_trajet_cat3_grp_OD.longueur_tot==trajets.df_trajet_cat3_grp_OD.longueur_tot.min()]\n",
    "            resultat.loc[i]=[b,ident_proche_bati,noeud_proche,tuple(df_finale.lignes.to_numpy()[0]), 'Deduction_trajet-ident connu_noeud_proche varie',df_finale.points.to_numpy()[0][-1]]\n",
    "            i+=1\n",
    "    elif ident_proche_bati in [b for a in resultat.loc[~resultat['trajet_court'].isna()].trajet_court.to_numpy() for b in a] : #si l'ident est sur un chemin deja traite\n",
    "        resultat_equi=resultat.loc[resultat.trajet_court.apply(lambda x : ident_proche_bati in x if isinstance(x,tuple) else False)].iloc[0]\n",
    "        trajet_equi=resultat_equi.trajet_court\n",
    "        trajet_court=trajet_equi[trajet_equi.index(ident_proche_bati):] \n",
    "        resultat.loc[i]=[b,ident_proche_bati,trajets.src,trajet_court, 'Deduction_trajet-ident sur chemin',resultat_equi.noeud_cat3]\n",
    "        i+=1\n",
    "        resultat.loc[i]=[b,ident_proche_bati,trajets.tgt,trajet_court, 'Deduction_trajet-ident sur chemin',resultat_equi.noeud_cat3]\n",
    "        i+=1\n",
    "    else : #sinon on deroule le calcul normalement\n",
    "        try :\n",
    "            trajets.calculs_trajets()\n",
    "        except v4.PasDeCheminCat3Error : \n",
    "            liste_bati_erreur.append(b)\n",
    "            continue\n",
    "        resultat.loc[i]=[b,ident_proche_bati,noeud_proche,trajets.trajet_court, 'Calcul_trajet',trajets.point_arrive]\n",
    "        i+=1\n",
    "        dico_df_tt_trajet[ident_proche_bati]=trajets.df_trajet_cat3_grp_OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#en cas d'arret pour erreur\n",
    "#reste_a_faire=export.iloc[:40000].loc[export.iloc[:40000].ID.isin(resultat.bati.tolist())].copy()\n",
    "index_arret=list_ids.index(resultat.tail(1).bati.values[0])+1\n",
    "index_bati_erreur=list_ids[index_arret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#SAVE RESULTATS FINAUX\n",
    "resultat.to_json(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\resultats_V2.json')\n",
    "\n",
    "dico_save2={k:v.to_dict() for k, v in dico_df_tt_trajet.items()}\n",
    "with open(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\df_tt_trajet_resultats_V2.json','w') as f:\n",
    "    f.write(json.dumps(dico_save2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#rappel\n",
    "with open(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\df_tt_trajet_resultats_V2.json','r') :\n",
    "    retour_dict=json.loads(f.read())\n",
    "dico_retour={k:pd.DataFrame.from_dict(v) for k, v in retour_dict.items()}\n",
    "r_tot=pd.read_json(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\resultats_V2.json')\n",
    "#donnees erreur\n",
    "with open(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\liste_bati_erreur.json','w') as f :\n",
    "    f.write(json.dumps(liste_bati_erreur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats_finaux=pd.read_json(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\resultats_V2.json')\n",
    "#ancienne version : r'D:\\Boulot\\Lin_bm\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\resultats_tot.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#ramener les trajets par batiment a une association 1..1 pour le calcul de la somme\n",
    "resultats_finaux_ordonnees=resultats_finaux.explode('trajet_court')\n",
    "resultats_finaux_ordonnees.reset_index(drop=True).to_json(r'D:\\Boulot\\Lin_bm\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\resultats_tot_ordonnes_V2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si besoin recup des donnees\n",
    "resultats_finaux_ordonnees=pd.read_json(r'D:\\Boulot\\Lin_bm\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\resultats_tot_ordonnes.json')\n",
    "\n",
    "#jointure avec bati pour recuperer nb personnes et geom\n",
    "resultats_finaux_ordonnees_pop=bati[['ID','PopT2016','geometry']].merge(resultats_finaux_ordonnees,left_on='ID', right_on='bati')\n",
    "\n",
    "#jointire spatiale avec EMC selon secteur pour connaitre le nombre total de deplacement par ident du rhv\n",
    "zones_emc=gp.read_file(r'D:\\Boulot\\Lin_bm\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\zones\\zonage_eda2017.shp')\n",
    "\n",
    "emc_nbpers_rhv=gp.sjoin(resultats_finaux_ordonnees_pop,zones_emc,how='left',op='intersects')\n",
    "\n",
    "#il y a qq batiment duplique, mais a cause de la cission des bati par le lCSQA, la prochaine fois prendre attribut IDBATI\n",
    "#emc_nbpers_rhv.loc[emc_nbpers_rhv.duplicated(['bati','trajet_court','PopT2016'], keep=False)].sort_values(['bati','trajet_court'])\n",
    "#recuperer le nombre de trajet moyen par secteur : \n",
    "trajMoyen_Emc=pd.read_csv(r'D:\\Boulot\\AffairesEnCours\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\EMC\\Linéarisation BdxM et EMC²\\trajet_moy_redress_coeq.csv')\n",
    "#affecter a chaque ident du rhv\n",
    "trajMoyParLigneRhv=emc_nbpers_rhv.merge(trajMoyen_Emc[['SEC','nb_traj_moy']], left_on='num_zone', right_on='SEC')\n",
    "#calcul du nombre de deplacements relatif a chaque batiment pour chaque identifiant\n",
    "trajMoyParLigneRhv['nbDeplacement']=trajMoyParLigneRhv['PopT2016']*trajMoyParLigneRhv['nb_traj_moy']\n",
    "#estimation du trafic par identifiant du rhv\n",
    "TraficMoyenEstime=trajMoyParLigneRhv.groupby('ident').agg({'nbDeplacement':sum,'PopT2016':sum,'nb_traj_moy':np.mean}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>nbDeplacement</th>\n",
       "      <th>PopT2016</th>\n",
       "      <th>nb_traj_moy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>7333</td>\n",
       "      <td>0.423666</td>\n",
       "      <td>1.339451</td>\n",
       "      <td>0.316298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770</th>\n",
       "      <td>22470</td>\n",
       "      <td>0.533505</td>\n",
       "      <td>1.686716</td>\n",
       "      <td>0.316298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15426</th>\n",
       "      <td>38974</td>\n",
       "      <td>0.678428</td>\n",
       "      <td>2.144902</td>\n",
       "      <td>0.316298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4659</th>\n",
       "      <td>10187</td>\n",
       "      <td>0.732721</td>\n",
       "      <td>2.316553</td>\n",
       "      <td>0.316298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>8097</td>\n",
       "      <td>0.756230</td>\n",
       "      <td>2.390878</td>\n",
       "      <td>0.316298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10131</th>\n",
       "      <td>21179</td>\n",
       "      <td>3916.350382</td>\n",
       "      <td>1974.187895</td>\n",
       "      <td>1.983778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11012</th>\n",
       "      <td>22962</td>\n",
       "      <td>4214.265872</td>\n",
       "      <td>2683.539505</td>\n",
       "      <td>1.570413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>5430</td>\n",
       "      <td>6568.206630</td>\n",
       "      <td>4369.978826</td>\n",
       "      <td>1.503029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>6509</td>\n",
       "      <td>7620.325399</td>\n",
       "      <td>9314.562460</td>\n",
       "      <td>0.818109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14493</th>\n",
       "      <td>34621</td>\n",
       "      <td>16461.650921</td>\n",
       "      <td>12618.690000</td>\n",
       "      <td>1.304545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18384 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ident  nbDeplacement      PopT2016  nb_traj_moy\n",
       "3222    7333       0.423666      1.339451     0.316298\n",
       "10770  22470       0.533505      1.686716     0.316298\n",
       "15426  38974       0.678428      2.144902     0.316298\n",
       "4659   10187       0.732721      2.316553     0.316298\n",
       "3619    8097       0.756230      2.390878     0.316298\n",
       "...      ...            ...           ...          ...\n",
       "10131  21179    3916.350382   1974.187895     1.983778\n",
       "11012  22962    4214.265872   2683.539505     1.570413\n",
       "2400    5430    6568.206630   4369.978826     1.503029\n",
       "2815    6509    7620.325399   9314.562460     0.818109\n",
       "14493  34621   16461.650921  12618.690000     1.304545\n",
       "\n",
       "[18384 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TraficMoyenEstime.sort_values('nbDeplacement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_bati_erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bati</th>\n",
       "      <th>ident</th>\n",
       "      <th>noeud_proche</th>\n",
       "      <th>trajet_court</th>\n",
       "      <th>comm</th>\n",
       "      <th>noeud_cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BATIMENT0000000257005411</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>(30604, 44711, 44712)</td>\n",
       "      <td>Calcul_trajet</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BATIMENT0000000257005409</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>(30604, 44711, 44712)</td>\n",
       "      <td>Deduction_trajet-ident connu_noeud_proche connu</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BATIMENT0000000257005395</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>(30604, 44711, 44712)</td>\n",
       "      <td>Deduction_trajet-ident connu_noeud_proche connu</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BATIMENT0000000257005393</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>(30604, 44711, 44712)</td>\n",
       "      <td>Deduction_trajet-ident connu_noeud_proche connu</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BATIMENT0000000257005408</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>(30604, 44711, 44712)</td>\n",
       "      <td>Deduction_trajet-ident connu_noeud_proche connu</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148000</th>\n",
       "      <td>BATIMENT0000000248395177</td>\n",
       "      <td>10685</td>\n",
       "      <td>16524.0</td>\n",
       "      <td>(10685, 10684, 32419)</td>\n",
       "      <td>Deduction_trajet-ident sur chemin</td>\n",
       "      <td>17414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148001</th>\n",
       "      <td>BATIMENT0000000248395177</td>\n",
       "      <td>10685</td>\n",
       "      <td>12273.0</td>\n",
       "      <td>(10685, 10684, 32419)</td>\n",
       "      <td>Deduction_trajet-ident sur chemin</td>\n",
       "      <td>17414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148002</th>\n",
       "      <td>BATIMENT0000000254021494</td>\n",
       "      <td>13633</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>(13633, 13952, 13661, 13660)</td>\n",
       "      <td>Calcul_trajet</td>\n",
       "      <td>5714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148003</th>\n",
       "      <td>BATIMENT0000000256984921</td>\n",
       "      <td>4441</td>\n",
       "      <td>20378.0</td>\n",
       "      <td>(4441,)</td>\n",
       "      <td>Deduction_trajet-ident sur chemin</td>\n",
       "      <td>3510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148004</th>\n",
       "      <td>BATIMENT0000000256984921</td>\n",
       "      <td>4441</td>\n",
       "      <td>3510.0</td>\n",
       "      <td>(4441,)</td>\n",
       "      <td>Deduction_trajet-ident sur chemin</td>\n",
       "      <td>3510.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148005 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            bati  ident  noeud_proche  \\\n",
       "0       BATIMENT0000000257005411  30604       26022.0   \n",
       "1       BATIMENT0000000257005409  30604       26022.0   \n",
       "2       BATIMENT0000000257005395  30604       26022.0   \n",
       "3       BATIMENT0000000257005393  30604       26022.0   \n",
       "4       BATIMENT0000000257005408  30604       26022.0   \n",
       "...                          ...    ...           ...   \n",
       "148000  BATIMENT0000000248395177  10685       16524.0   \n",
       "148001  BATIMENT0000000248395177  10685       12273.0   \n",
       "148002  BATIMENT0000000254021494  13633        1611.0   \n",
       "148003  BATIMENT0000000256984921   4441       20378.0   \n",
       "148004  BATIMENT0000000256984921   4441        3510.0   \n",
       "\n",
       "                        trajet_court  \\\n",
       "0              (30604, 44711, 44712)   \n",
       "1              (30604, 44711, 44712)   \n",
       "2              (30604, 44711, 44712)   \n",
       "3              (30604, 44711, 44712)   \n",
       "4              (30604, 44711, 44712)   \n",
       "...                              ...   \n",
       "148000         (10685, 10684, 32419)   \n",
       "148001         (10685, 10684, 32419)   \n",
       "148002  (13633, 13952, 13661, 13660)   \n",
       "148003                       (4441,)   \n",
       "148004                       (4441,)   \n",
       "\n",
       "                                                   comm  noeud_cat3  \n",
       "0                                         Calcul_trajet     10489.0  \n",
       "1       Deduction_trajet-ident connu_noeud_proche connu     10489.0  \n",
       "2       Deduction_trajet-ident connu_noeud_proche connu     10489.0  \n",
       "3       Deduction_trajet-ident connu_noeud_proche connu     10489.0  \n",
       "4       Deduction_trajet-ident connu_noeud_proche connu     10489.0  \n",
       "...                                                 ...         ...  \n",
       "148000                Deduction_trajet-ident sur chemin     17414.0  \n",
       "148001                Deduction_trajet-ident sur chemin     17414.0  \n",
       "148002                                    Calcul_trajet      5714.0  \n",
       "148003                Deduction_trajet-ident sur chemin      3510.0  \n",
       "148004                Deduction_trajet-ident sur chemin      3510.0  \n",
       "\n",
       "[148005 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bati</th>\n",
       "      <th>ident</th>\n",
       "      <th>noeud_proche</th>\n",
       "      <th>trajet_court</th>\n",
       "      <th>comm</th>\n",
       "      <th>noeud_cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BATIMENT0000000257005411</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>30604</td>\n",
       "      <td>Calcul_trajet</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BATIMENT0000000257005411</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>44711</td>\n",
       "      <td>Calcul_trajet</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BATIMENT0000000257005411</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>44712</td>\n",
       "      <td>Calcul_trajet</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BATIMENT0000000257005409</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>30604</td>\n",
       "      <td>Deduction_trajet-ident connu_noeud_proche connu</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BATIMENT0000000257005409</td>\n",
       "      <td>30604</td>\n",
       "      <td>26022.0</td>\n",
       "      <td>44711</td>\n",
       "      <td>Deduction_trajet-ident connu_noeud_proche connu</td>\n",
       "      <td>10489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148002</th>\n",
       "      <td>BATIMENT0000000254021494</td>\n",
       "      <td>13633</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>13952</td>\n",
       "      <td>Calcul_trajet</td>\n",
       "      <td>5714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148002</th>\n",
       "      <td>BATIMENT0000000254021494</td>\n",
       "      <td>13633</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>13661</td>\n",
       "      <td>Calcul_trajet</td>\n",
       "      <td>5714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148002</th>\n",
       "      <td>BATIMENT0000000254021494</td>\n",
       "      <td>13633</td>\n",
       "      <td>1611.0</td>\n",
       "      <td>13660</td>\n",
       "      <td>Calcul_trajet</td>\n",
       "      <td>5714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148003</th>\n",
       "      <td>BATIMENT0000000256984921</td>\n",
       "      <td>4441</td>\n",
       "      <td>20378.0</td>\n",
       "      <td>4441</td>\n",
       "      <td>Deduction_trajet-ident sur chemin</td>\n",
       "      <td>3510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148004</th>\n",
       "      <td>BATIMENT0000000256984921</td>\n",
       "      <td>4441</td>\n",
       "      <td>3510.0</td>\n",
       "      <td>4441</td>\n",
       "      <td>Deduction_trajet-ident sur chemin</td>\n",
       "      <td>3510.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428916 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            bati  ident  noeud_proche trajet_court  \\\n",
       "0       BATIMENT0000000257005411  30604       26022.0        30604   \n",
       "0       BATIMENT0000000257005411  30604       26022.0        44711   \n",
       "0       BATIMENT0000000257005411  30604       26022.0        44712   \n",
       "1       BATIMENT0000000257005409  30604       26022.0        30604   \n",
       "1       BATIMENT0000000257005409  30604       26022.0        44711   \n",
       "...                          ...    ...           ...          ...   \n",
       "148002  BATIMENT0000000254021494  13633        1611.0        13952   \n",
       "148002  BATIMENT0000000254021494  13633        1611.0        13661   \n",
       "148002  BATIMENT0000000254021494  13633        1611.0        13660   \n",
       "148003  BATIMENT0000000256984921   4441       20378.0         4441   \n",
       "148004  BATIMENT0000000256984921   4441        3510.0         4441   \n",
       "\n",
       "                                                   comm  noeud_cat3  \n",
       "0                                         Calcul_trajet     10489.0  \n",
       "0                                         Calcul_trajet     10489.0  \n",
       "0                                         Calcul_trajet     10489.0  \n",
       "1       Deduction_trajet-ident connu_noeud_proche connu     10489.0  \n",
       "1       Deduction_trajet-ident connu_noeud_proche connu     10489.0  \n",
       "...                                                 ...         ...  \n",
       "148002                                    Calcul_trajet      5714.0  \n",
       "148002                                    Calcul_trajet      5714.0  \n",
       "148002                                    Calcul_trajet      5714.0  \n",
       "148003                Deduction_trajet-ident sur chemin      3510.0  \n",
       "148004                Deduction_trajet-ident sur chemin      3510.0  \n",
       "\n",
       "[428916 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats_finaux_ordonnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
