{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LINEARISATION UNIQUE DES TRAFICS SUR BORDEAUX METROPOLE**\n",
    "> Traitements à mettre en oeuvre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys #c'est pas propre mais pour le moment pour importer mes modules perso dans le notebook je ne sais pas faire\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Outils\\Outils\\Martin_Perso')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\otv\\otv\\Transfert_Donnees')\n",
    "sys.path.append(r'C:\\Users\\martin.schoreisz\\git\\Lin_uniq_BdxM\\Lin_uniq_BdxM\\Traitements')\n",
    "import Connexion_Transfert as ct\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import MultiPoint, Polygon, box\n",
    "import re\n",
    "from difflib import get_close_matches,SequenceMatcher\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from Outils import creer_graph, plus_proche_voisin,nb_noeud_unique_troncon_continu,verif_index\n",
    "\n",
    "from Simplifier_Rdpt import creer_dico_noeud_rdpt,simplifier_noeud_rdpt,maj_graph_rdpt, donnees_tot_rd_pt\n",
    "import Estim_trafic as et\n",
    "import Comptage as Cpt\n",
    "import Affectation_pt_comptage as ap\n",
    "from MMM import import_fichiers_mmm\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "\n",
    "from Base_BdTopo.Import_outils import import_donnes_base\n",
    "from Base_BdTopo.Rond_points import identifier_rd_pt\n",
    "from Base_BdTopo.Regroupement_correspondance import *\n",
    "from Base_BdTopo.Troncon_elementaire import *\n",
    "from Base_BdTopo.Troncon_base import *\n",
    "from Base_BdTopo.Gestion_2_chaussee import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Regrouper les troncons du filaire de voie\n",
    ">Les troncons du filaire de voie sont regroupés d'abord uniquement avec les troncons de cat_rhv égal à 1,2,3,61,62,63, pour pouvoir réaliser des troncon de trafic homogènes tous reliés entre eux.\n",
    "<br> Ensuite, un deuxième regroupement comprenant l'ensemble des troncons de cat_rhv permetd'affiner le diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 1.1 Import du fichier final\n",
    "le fichier shape est vérifié à la main car l'affectation automatique n'est pas 100% fiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour info : lire le graph issu de la methode decrite dessous\n",
    "with ct.ConnexionBdd('local_otv') as c :\n",
    "    graph_filaire_123 = gp.read_postgis('select * from linearisation_bm.graph_rhv_123_v2', c.connexionPsy)\n",
    "    graph_filaire_123_vertex = gp.read_postgis('select id,cnt,chk,ein,eout,the_geom as geom from linearisation_bm.graph_rhv_123_v2_vertices_pgr', c.connexionPsy)\n",
    "    graph_filaire = gp.read_postgis('select * from linearisation_bm.graph_rhv_complet', c.connexionPsy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_rhv_groupe_123=graph_filaire_123\n",
    "\"\"\"gdf_rhv_groupe_123=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_groupe_123_v2.shp').merge(\n",
    "    graph_filaire_123[['ident','source','target']], on='ident', how='left')\"\"\"\n",
    "gdf_rhv_groupe=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\rhv_grp.shp').merge(\n",
    "    graph_filaire[['ident','source','target']], on='ident', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 1.2 Méthode\n",
    " pour information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. import du fichier de filaire de base\n",
    "gdf_rhv=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\Bdx-Metro\\Filaire_voie\\FV_TRONC_L.shp')\n",
    "# 2. mise en forme\n",
    "gdf_rhv.columns=[a.lower() for a in gdf_rhv.columns] #nom de colonne en minuscule\n",
    "gdf_rhv.rename(columns={'gid':'id','nom_voie' : 'numero'},inplace=True)\n",
    "gdf_rhv=gdf_rhv.loc[~gdf_rhv.id.isna()].copy()\n",
    "gdf_rhv['id_ign']=gdf_rhv.ident.apply(lambda x : 'TRONROUT'+str(x))\n",
    "gdf_rhv=gdf_rhv.loc[~gdf_rhv.cat_rhv.isin(['98','99'])].copy()\n",
    "gdf_rhv['nature']=gdf_rhv.apply(lambda x : 'Route à 2 chaussées' if x['rgraph_dbl']==0 else 'Route à 1 chaussée', axis=1)\n",
    "gdf_rhv['nature']=gdf_rhv.apply(lambda x : 'Bretelle' if x['cat_dig']=='8' else x['nature'], axis=1)\n",
    "gdf_rhv['numero']=gdf_rhv.apply(lambda x : 'Bretelle '+x['numero'] if x['cat_dig']=='8' else x['numero'], axis=1)\n",
    "gdf_rhv['sens']=gdf_rhv.apply(lambda x : 'Direct' if x['rgraph_dbl']==0 else 'Double', axis=1)\n",
    "gdf_rhv['codevoie_d']='NR'\n",
    "gdf_rhv['importance']=gdf_rhv['cat_dig']\n",
    "gdf_rhv['id']=gdf_rhv.id.apply(lambda x : int(x))\n",
    "#gdf_rhv.loc[gdf_rhv.nom_voie.isna()] #verif des nom_voie null : 2 lignes, cf traitements plus loins\n",
    "#filtrer les voies cylcables et autres\n",
    "gdf_rhv_filtre=gdf_rhv.loc[~gdf_rhv.cat_dig.isin(['6','7','9','10'])].copy()\n",
    "\n",
    "# 3. creer le graph en bdd\n",
    "#creer_graph(gdf_rhv_filtre.loc[gdf_rhv_filtre.cat_rhv.isin(['1','2','3','33','61','62','63'])],\n",
    "            #'local_otv',schema='linearisation_bm',table='graph_rhv_123',table_vertex='graph_rhv_123_vertices_pgr')\n",
    "creer_graph(gdf_rhv_filtre,'local_otv',schema='linearisation_bm',table='graph_rhv_complet',table_vertex='graph_rhv_complet_vertices_pgr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    }
   ],
   "source": [
    "# 4. initialiser les paramètre de regroupement\n",
    "df=import_donnes_base('local_otv','linearisation_bm', 'graph_rhv_complet','graph_rhv_complet_vertices_pgr')\n",
    "df2_chaussees=df.loc[df.nature.isin(['Autoroute', 'Quasi-autoroute', 'Route à 2 chaussées'])]\n",
    "df_avec_rd_pt,carac_rd_pt,lign_entrant_rdpt=identifier_rd_pt(df)\n",
    "df_lignes=df_avec_rd_pt.set_index('id_ign')#mettre l'id_ign en index\n",
    "bretelle=df_avec_rd_pt.loc[df_avec_rd_pt['nature']=='Bretelle'].copy()\n",
    "bretelle_tri=bretelle.loc[bretelle.length.sort_values(ascending=False).index.tolist()].id_ign.tolist()\n",
    "sans_bretelle=df_avec_rd_pt.loc[df_avec_rd_pt['nature']!='Bretelle'].copy()\n",
    "list_sans_bretelle=sans_bretelle.id_ign.tolist()\n",
    "list_tri_longueur=sans_bretelle.loc[sans_bretelle.length.sort_values(ascending=False).index.tolist()].id_ign.tolist()\n",
    "list_id_ign=bretelle_tri+list_tri_longueur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 5. appel fonction de grouepement pour creer des idtronc pour uniquement voies de 1 à 3 et d'un autre coté pour toute les voies\n",
    "df_affectation, dico_erreur, lignes_traitees, lignes_non_traitees=regrouper_troncon(\n",
    "    list_id_ign, df_avec_rd_pt, carac_rd_pt,df2_chaussees,[])\n",
    "\n",
    "# 6. mise en forme et export\n",
    "gdf_rhv_groupe=gdf_rhv_filtre.merge(df_affectation, left_on='id_ign', right_on='id', how='left')\n",
    "gdf_rhv_groupe.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\rhv_grp_v2.shp')\n",
    "#gdf_rhv_groupe_123=gdf_rhv_filtre.merge(df_affectation, left_on='id_ign', right_on='id', how='left')\n",
    "#gdf_rhv_groupe_123.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_groupe_123.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MISE EN FORME DES COMPTAGES PONCTUELS\n",
    "Pour ces comptages l'idée c'est de réussir à regrouper les comptages par un idtronc issu de la detection des troncon elementaire. ça a du sens car pour un comptage ponctuel normalement les 2 sens de cicru sont sur un troncon unique. DE plus, les ens circu, noms de voie et autres attributs permettant de regrouper les comptages sont de qualité trop variable pour s'appuyer uniquement dessus. et enfin, peu de 2*2 vois sont meusrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    }
   ],
   "source": [
    "affect_finale,cpt_pct_l93=Cpt.traitements_bdxm_pct(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\Bdx-Metro\\comptages\\base_comptages_routiers_finale.xlsx',gdf_rhv_groupe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MISE EN FORME DES COMPTAGES PERMANENTS\n",
    "Pour ces compteurs on va regrouper en séparant les siredo des boucles liées au système gertrude. Pour les siredo pas de pb, pour les autre sc'est plus compliqué car les références de localiusation varient parfois. Il y a donc une phase de regroupement manuel à la fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 2.1 Import du fichier final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import fichier corrige_final\n",
    "cpt_perm_final=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\cpt_perm_groupe.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 2.1 Méthode\n",
    "Pour info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#creer un gdf avec la fusion des points et des données de comptages non nulles\n",
    "cpt_brut=pd.read_excel(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\Bdx-Metro\\comptages\\comptage_trafic_final.xls')\n",
    "cpt_brut.columns=[a.lower() for a in cpt_brut.columns]\n",
    "cpt_brut=cpt_brut.loc[~cpt_brut.mjo_val.isna()].copy()\n",
    "pt_cpt_perm=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\Bdx-Metro\\comptages\\PC_CAPTE_P.shp')\n",
    "pt_cpt_perm.columns=[a.lower() for a in pt_cpt_perm.columns]\n",
    "pt_cpt_perm=pt_cpt_perm.merge(cpt_brut, on='ident')\n",
    "pt_cpt_perm['nom_voie']=pt_cpt_perm.nom_voie.apply(lambda x : re.sub(('é|è|ê'),'e',x.lower().replace('  ',' ')))#mise en forme nom de voie\n",
    "\n",
    "#regrouper les comptages\n",
    "#un compteur peut caracteriser 1 ligne, ou 2 compteur 1 ligne ou 2 compteurs 2 lignes, dc les compteurs ne vont pas toujours par deux\n",
    "\n",
    "#regrouper geographiquement\n",
    "pt_cpt_perm['x_l93']=pt_cpt_perm.geometry.apply(lambda x : x.x)\n",
    "pt_cpt_perm['y_l93']=pt_cpt_perm.geometry.apply(lambda x : x.y)\n",
    "data_test_clust=[[x, y] for x, y in zip(pt_cpt_perm.x_l93.tolist(), pt_cpt_perm.y_l93.tolist())]\n",
    "db = DBSCAN(eps=200, min_samples=2).fit(data_test_clust)\n",
    "labels = db.labels_\n",
    "pt_cpt_perm['n_cluster']=labels\n",
    "\n",
    "#correspondance nom_rue\n",
    "#analyser les noms de commune : \n",
    "#grp_nom_voie.nom_voie.apply(lambda x : x.split()[0]).unique()#liste des permiers mots\n",
    "#grp_nom_voie.loc[grp_nom_voie.nom_voie.apply(lambda x : x.split()[0]=='carbon')].nom_voie.unique() #test des valeusr\n",
    "dico_commune={'le bouscat','le haillan','bordeaux','pessac','talence', 'merignac','st medard','carbon blanc',\n",
    "       'begles', 'eysines','villenave d\\'ornon','bruges','gradignan','bassens','cenon','floirac','pessa','lormont', 'artigues'}\n",
    "dico_type_voie={'allee' : ['all.','allee', 'allees'],'avenue': ['av', 'av.', 'avenue'], 'boulevard' : ['blvd'],\n",
    "               'bretelle' : 'bretelle', 'cours' : ['crs','cours'], 'cote' : ['côte'], 'place':['pl'], 'route':['route', 'rte'],'rue':['rue'],\n",
    "               'voie':['voie']}\n",
    "def decoupe_nom_voie(nom_voie) : \n",
    "    for c in dico_commune : \n",
    "        if nom_voie[:len(c)]==c :\n",
    "            commune=nom_voie[:len(c)]\n",
    "            nom_voie=nom_voie[len(c):].strip()\n",
    "    for k, v in dico_type_voie.items() : \n",
    "        if any([a for a in nom_voie.split() if a in v])  : \n",
    "            caractere=[a for a in nom_voie.split() if a in v][0]\n",
    "            type_voie=k\n",
    "            nom_voie=' '.join([n for n in nom_voie.split() if n!=caractere])\n",
    "            break\n",
    "    else : type_voie=None\n",
    "    for test in ['avant','apres'] :\n",
    "        if test in nom_voie : \n",
    "            return nom_voie.split(test)[0].strip(), test,nom_voie.split(test)[1].strip(), commune, type_voie\n",
    "    else : return nom_voie, nom_voie,nom_voie,commune,type_voie\n",
    "\n",
    "pt_cpt_perm['nom_rue']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[0])\n",
    "pt_cpt_perm['localisant']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[1])\n",
    "pt_cpt_perm['rue_refer']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[2])\n",
    "pt_cpt_perm['commune']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[3])\n",
    "pt_cpt_perm['type_voie']=pt_cpt_perm.nom_voie.apply(lambda x : decoupe_nom_voie(x)[4])\n",
    "pt_cpt_perm.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\pt_cpt_perm.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>#### 2.2.1 SIREDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "siredo=pt_cpt_perm.loc[pt_cpt_perm['type']=='SIREDO'].copy()#isoler siredo\n",
    "cross_join=siredo.assign(key=1).merge(siredo.assign(key=1), on='key').drop('key',axis=1)#calcul des distances\n",
    "cross_join['distance']=cross_join.apply(lambda x : x['geometry_x'].distance(x['geometry_y']),axis=1)\n",
    "cross_join_filtre=cross_join[[c for c in cross_join.columns if c[-2:]=='_x']+['distance','ident_y']].rename(columns=\n",
    "              {c : c[:-2] for c in cross_join.columns if c[-2:]=='_x'}).copy()#filtre des attribut\n",
    "cross_join_filtre=cross_join_filtre.loc[(cross_join_filtre['ident']!=cross_join_filtre['ident_y'])].copy()\n",
    "siredo_proches=cross_join_filtre.loc[(cross_join_filtre.groupby('ident')['distance'].transform(min)==\n",
    "                                      cross_join_filtre['distance'])].copy()#plus proche voisin\n",
    "siredo_proches['id_grpsiredo']=siredo_proches.reset_index().index\n",
    "id_siredo_proches=(pd.concat([siredo_proches[['ident','ident_y', 'id_grpsiredo']],\n",
    "           siredo_proches[['ident_y','ident', 'id_grpsiredo']].rename(columns={\n",
    "    'ident_y':'ident', 'ident':'ident_y'})],sort=False).sort_values('ident').\n",
    "    reset_index().drop_duplicates('index').drop_duplicates(['ident','ident_y']).drop('index',axis=1))\n",
    "cle_assoc_siredo=pd.concat([id_siredo_proches[['ident','id_grpsiredo']],id_siredo_proches[['ident_y','id_grpsiredo']].rename(columns={\n",
    "    'ident_y':'ident'})]).sort_values('id_grpsiredo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>#### 2.2.2 Gertrude\n",
    "> au final ce n'est pas très efficace, et un renseignement des regroupement a la ain aurait été plus rapide. il sera important si de nouvelles stations sont posées de fournir de suite un identifiant de regroupement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gertrude=pt_cpt_perm.loc[pt_cpt_perm['type']=='BOUCLE'].copy()#isoler les boucles\n",
    "gertrude['x']=gertrude.geometry.apply(lambda x : x.x)\n",
    "gertrude['y']=gertrude.geometry.apply(lambda x : x.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#si c'est sur le mm idtronc on regroupe\n",
    "\n",
    "#rappatrier le numero d'id_tronc pour chaque comptage\n",
    "#trouver la distance min à chaque objet ligne\"du rhv groupe\n",
    "grp_troncon_temp=gertrude.copy()\n",
    "grp_troncon_temp.geometry=grp_troncon_temp.buffer(20)#passer la geom en buffer\n",
    "intersct_buff_20=gp.sjoin(grp_troncon_temp,gdf_rhv_groupe,how='left',op='intersects')\n",
    "intersct_buff_20.geometry=gertrude.geometry#repasser la geom en point\n",
    "intersct_buff_20=intersct_buff_20.merge(gdf_rhv_groupe[['ident','geometry']], left_on='ident_right', right_on='ident')\n",
    "intersct_buff_20['dist_pt_ligne']=intersct_buff_20.apply(lambda x : x['geometry_x'].distance(x['geometry_y']), axis=1) #définir la disance entre les points et ligne\n",
    "joint_dist_min=intersct_buff_20.loc[intersct_buff_20.groupby('ident_left')['dist_pt_ligne'].transform(min)==intersct_buff_20['dist_pt_ligne']][['ident_left','idtronc','numero']].rename(\n",
    "    columns={'ident_left':'ident'}).copy()#ne garder que la ligne la plus proche\n",
    "grp_troncon=gertrude.merge(joint_dist_min, on='ident',how='left')#df finale\n",
    "\n",
    "#regrouper\n",
    "grp_idtronc=grp_troncon.groupby('idtronc')['ident'].agg(lambda x : tuple(x))\n",
    "grp_idtronc=grp_idtronc.loc[grp_idtronc.apply(lambda x : len(x)>1)].reset_index().copy()\n",
    "grp_idtronc['id_grp']=grp_idtronc.ident.rank()\n",
    "#mettre en forme\n",
    "grp_idtronc=pd.DataFrame([(a,g) for i,g in zip(grp_idtronc.ident.tolist(),grp_idtronc.id_grp.tolist()) for a in i], columns=['ident','id_grp'])\n",
    "grp_final=grp_idtronc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# trouver les points qui restent et préparer un regrouepement par commune, nom de rue, distance et se,s\n",
    "\n",
    "#points qui restent\n",
    "gertrude_etape2=gertrude.loc[~gertrude['ident'].isin(grp_idtronc.ident.tolist())].copy()\n",
    "#comparer les noms\n",
    "cross_join=gertrude_etape2[['gid','geometry','ident','nom_voie', 'sens_cir','commune', 'nom_rue', 'localisant','rue_refer','type_voie']].assign(key=1).merge(\n",
    "    gertrude_etape2[['gid','geometry','ident','nom_voie', 'sens_cir','commune', 'nom_rue', 'localisant','rue_refer','type_voie']].assign(key=1), on='key').drop('key',axis=1)#calcul des distances\n",
    "cross_join['distance']=cross_join.apply(lambda x : x['geometry_x'].distance(x['geometry_y']),axis=1)\n",
    "cross_join['comp_nom_rue']=cross_join.apply(lambda x : SequenceMatcher(None,x['nom_rue_x'], x['nom_rue_y']).ratio(), axis=1)#affecter une note a cahque relation\n",
    "\n",
    "#vérifier que les sens de cicru sont cohérents et ne garder que les lignes avec un sens ok, un nom de voie proche et une distance proche\n",
    "gertrude_join=cross_join.loc[(cross_join['comp_nom_rue']>0.6) & (cross_join['distance']<1000) & (cross_join['commune_x']==cross_join['commune_y']) & \n",
    "                             (cross_join['type_voie_x']==cross_join['type_voie_y'])].copy()\n",
    "#on ajoute un attribut de verif du sens\n",
    "def verif_sens(s1,s2) : \n",
    "    for sens in [['Sens Sortant', 'Sens Entrant'],['Sens N > S', 'Sens S > N'], ['Sens Nord > Sud', 'Sens Sud > Nord'],['Nord > Sud', 'Sud > Nord'],\n",
    "                ['Boulevards Nord > Sud', 'Boulevards Sud > Nord']] :\n",
    "        if s1 in sens and s2 in sens : \n",
    "            if s1!=s2 : \n",
    "                return True\n",
    "        else : \n",
    "            continue\n",
    "    return False\n",
    "gertrude_join['valid_sens']=gertrude_join.apply(lambda x : verif_sens(x['sens_cir_x'],x['sens_cir_y']),axis=1)  \n",
    "gertrude_join['id_grp']=gertrude_join.sort_values('ident_x').ident_x.rank(method=\"min\")\n",
    "gertrude_grp=gertrude_join.loc[gertrude_join['valid_sens']][['ident_x','ident_y','distance', 'comp_nom_rue', 'valid_sens','id_grp']].sort_values('ident_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#obtenir une liste des ident qui se regroupent\n",
    "list_id_grp=pd.concat([gertrude_grp[['ident_x','id_grp']],gertrude_grp[['ident_y','id_grp']].rename(columns={'ident_y' : 'ident_x'})]).drop_duplicates([\n",
    "    'ident_x','id_grp']).groupby('id_grp').ident_x.agg(lambda x : set(sorted(tuple(x)))).tolist()\n",
    "dico={}\n",
    "for e,c in enumerate(gertrude_grp.ident_x.tolist()) : \n",
    "    for l in list_id_grp : \n",
    "        if c in l :\n",
    "            #print('c dans l','c : ',c,'l :',l)\n",
    "            if c not in dico.keys() :\n",
    "                dico[c]=list(l)\n",
    "            else : \n",
    "                dico[c]+=list(l)\n",
    "list_id_grp_temp=set([ v for v in {k : tuple(set(sorted(dico[k]))) for k in dico.keys()}.values()])\n",
    "list_id_grp_final=set(v for v in {c :b for c in gertrude_grp.ident_x.tolist() \n",
    " for b in [a for a in list_id_grp_temp if c in a] \n",
    " if len(b) == max([len(c) for c in [a for a in list_id_grp_temp if c in a]])}.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#affecter un identifiant\n",
    "def groupe_pt_gertrude_etape2(df_local) : \n",
    "    \"\"\"\n",
    "    regrouper les points à partir d'une liste d'ident selon l'ordre d'apparition \n",
    "    \"\"\"\n",
    "    limite_box=MultiPoint([(a.x,a.y) for a in df_local.itertuples()]).bounds\n",
    "    plg_long, plg_larg=limite_box[2]-limite_box[0],limite_box[3]-limite_box[1]\n",
    "    if max(plg_long,plg_larg)==plg_long : \n",
    "        df_local['next_sens']=df_local.sort_values('x').sens_cir.shift(-1,fill_value='NC')\n",
    "        df_local['prev_sens']=df_local.sort_values('x').sens_cir.shift(1,fill_value='NC')\n",
    "    else : \n",
    "        df_local['next_sens']=df_local.sort_values('y').sens_cir.shift(-1,fill_value='NC')\n",
    "        df_local['prev_sens']=df_local.sort_values('y').sens_cir.shift(1,fill_value='NC')\n",
    "    df_local['sens_comp']=df_local.apply(lambda x : x.prev_sens if x.next_sens=='NC' else x.next_sens,axis=1)\n",
    "    df_local['verif_sens']=df_local.apply(lambda x : verif_sens(x['sens_cir'],x['sens_comp']),axis=1)\n",
    "    df_local['id_grp']=-99\n",
    "    i=0\n",
    "    while i < len(df_local)-1:\n",
    "        if df_local.iloc[i].verif_sens : \n",
    "            df_local.loc[df_local.index.isin(df_local.iloc[i:i+2].index.tolist()),'id_grp']=i\n",
    "            i+=2\n",
    "        else : \n",
    "            i+=1\n",
    "    return\n",
    "\n",
    "# à partior de la liste des ident groupé : \n",
    "grp_final2=grp_final.copy()\n",
    "# on selectionne ces points dans la df\n",
    "increment=grp_final2.id_grp.max()\n",
    "for l in list_id_grp_final : \n",
    "    #if 'Z8CT13' not in l : continue\n",
    "    df_local=gertrude_etape2.loc[gertrude_etape2.ident.isin(l)].copy()\n",
    "    if len(df_local)==1:\n",
    "        continue\n",
    "    if len(df_local)==2 : \n",
    "        if (gertrude_join.loc[(gertrude_join.ident_x.isin(l)) & (gertrude_join['ident_x'] != gertrude_join['ident_y'])].valid_sens).all() : \n",
    "            increment+=1\n",
    "            df_local['id_grp']=increment\n",
    "            grp_final2=pd.concat([grp_final2,df_local[['ident','id_grp']]],sort=False)\n",
    "    else :\n",
    "        groupe_pt_gertrude_etape2(df_local)\n",
    "        increment+=grp_final2.id_grp.max()\n",
    "        df_local.loc[df_local['id_grp']!=-99,'id_grp']=df_local['id_grp']+increment\n",
    "        grp_final2=pd.concat([df_local[['ident','id_grp']],grp_final2],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#rappatrier l'id_grp sur les données de base et export pour modif manuelle\n",
    "gertrude.merge(grp_final2, on='ident',how='left').to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gertrude.shp')\n",
    "\n",
    "#import des modifs manuelles et mise en forme finale\n",
    "gertrude_manu=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gertrude.shp')\n",
    "gertrude_manu.loc[(gertrude_manu.id_grp.isna()) | (gertrude_manu.id_grp==-99),'id_grp']=gertrude_manu.loc[(gertrude_manu.id_grp.isna()) | (gertrude_manu.id_grp==-99),'id_grp'].reset_index().index + gertrude_manu.id_grp.max()\n",
    "gertrude_manu.loc[gertrude_manu.type_grp.isnull(),'type_grp']='auto'\n",
    "#export pour dernière modif manuelle\n",
    "gertrude_manu.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gertrude_final.shp')\n",
    "\n",
    "#fichier final\n",
    "gertrude_fin=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gertrude_final.shp')\n",
    "#concat avec les siredo\n",
    "cle_assoc_siredo['id_grpsiredo']=cle_assoc_siredo['id_grpsiredo']+gertrude_fin.id_grp.max()\n",
    "cpt_perm_final=pd.concat([gertrude_fin,siredo.merge(cle_assoc_siredo, on='ident').rename(columns={'id_grpsiredo':'id_grp'})],axis=0, sort=False)\n",
    "cpt_perm_final.to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\cpt_perm_groupe.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Affecter du trafic au filaire de voie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### On commence par affecter le trafic aux troncons des catégories 1,2,3 à partirdes comptages permanents.<br> Pour le détail des fonctions cf module Affectation_pt_comptage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    }
   ],
   "source": [
    "gdf_rhv_cpt_perm_123,lgn_proche_perm=ap.affectation_cpt_perm(cpt_perm_final,gdf_rhv_groupe,gdf_rhv_groupe_123,10)\n",
    "#ap.export_cpt_perm_linearises(gdf_rhv_cpt_perm_123,r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_123_cpt_perm.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### ensuite les comptages ponctuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    }
   ],
   "source": [
    "#affectation des comptages ponctuels et exports\n",
    "gdf_traf_tot=ap.affectation_cpt_ponct(cpt_pct_l93, affect_finale, lgn_proche_perm, gdf_rhv_groupe, 10, gdf_rhv_groupe_123, gdf_rhv_cpt_perm_123)\n",
    "#ap.export_cpt_ponct_linearises(gdf_traf_tot,r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_123_cpt_perm-ponct.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MMM\n",
    "En premier lieu il faut mettre à jour les attributs en renomant de façon explicite puis en faisant la somme des 2 sens de circulation pour les voies doucble sens cf module MMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fichier_src_simpl=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\MMM\\MMM_Maj_EDA2017\\simplifie\\MMM_simple_2019.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#creer graph et importer \n",
    "creer_graph(fichier_src_simpl, 'local_otv',id_name='NO', schema='linearisation_bm', table='mmm_graph_2019', table_vertex='mmm_graph_2019_vertices_pgr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#importer le graph\n",
    "with ct.ConnexionBdd('local_otv') as c :\n",
    "    graph_mmm_filaire = gp.read_postgis('select * from linearisation_bm.mmm_graph_2019', c.connexionPsy)\n",
    "    graph_mmm_filaire_vertex = gp.read_postgis('select * from linearisation_bm.mmm_graph_2019_vertices_pgr', c.connexionPsy,geom_col='the_geom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer les fichiers finaux\n",
    "mmm_simple,cle_mmm_rhv=import_fichiers_mmm(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_source\\MMM\\MMM_Maj_EDA2017\\simplifie\\MMM_simple_2019.shp',\n",
    "                                            r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\appariementV0.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affecter du trafic aux voies non connues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POUR TEST SUR UN NOEUD UNIQUEMNET\n",
    "gdf_base2=gdf_traf_tot.copy()\n",
    "gdf_rhv_rdpt_simple3=gdf_rhv_rdpt_simple.copy()\n",
    "#remplacement des sources et targets : \n",
    "simplifier_noeud_rdpt(gdf_rhv_rdpt_simple3, dico_noeud)\n",
    "#puis recalculer le count du nb de ligne par noeud (en otant les lignes qui font les rdpoints)\n",
    "df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple3)[2:4]\n",
    "liste_noeud_traite=[]\n",
    "liste_noeud_mmm=[]\n",
    "dico_erreur={}\n",
    "num_noeud=2082\n",
    "gdf_rhv_rdpt_simple3=verif_index(gdf_rhv_rdpt_simple3,'idtronc')#Îsi idtronc est en index on le repasse dans les colonnes\n",
    "\n",
    "df_troncon_noeud=et.carac_troncon_noeud(gdf_rhv_rdpt_simple3, gdf_base2, graph_filaire_123_vertex,num_noeud,df_noeuds,lgn_rdpt)\n",
    "  #si tous les trafics du noeud sont déjà renseignés on passe\n",
    "  #determiner si on est dans le cas d'une voie pouvant etre estimée par calcul (3 troncon dont 1 seul manquant) ou par analogie avec le MMM\n",
    "et.maj_trafic_3tronc(df_troncon_noeud)\n",
    "df_update_traf=df_troncon_noeud[['idtronc','tmjo_2_sens','type_cpt']].set_index('idtronc').drop_duplicates()\n",
    "df_update_traf.update(pd.DataFrame.from_records(dico_corection_calcul_3_voies, columns=['idtronc','tmjo_2_sens', 'type_cpt']).set_index('idtronc').fillna('NC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmjo_2_sens</th>\n",
       "      <th>type_cpt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idtronc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12218.0</th>\n",
       "      <td>-99</td>\n",
       "      <td>estim_manuelle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tmjo_2_sens        type_cpt\n",
       "idtronc                             \n",
       "12218.0 -99           estim_manuelle"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_update_traf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOUVELLE METHODE POUR TRAITER LES NOEUDS ESTIMABLES 3 VOIES\n",
    "gdf_base=gdf_traf_tot.copy()\n",
    "gdf_rhv_rdpt_simple=gdf_base.loc[~gdf_base.ident.isin(lgn_rdpt.ident.to_list())].copy()\n",
    "#remplacement des sources et targets : \n",
    "simplifier_noeud_rdpt(gdf_rhv_rdpt_simple, dico_noeud)\n",
    "#puis recalculer le count du nb de ligne par noeud (en otant les lignes qui font les rdpoints)\n",
    "cnt_maj=maj_graph_rdpt(gdf_rhv_rdpt_simple)\n",
    "noeuds_estim, noeuds_grp, df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple)\n",
    "dico_erreur,dico_noeud_3_voies, liste_noeud_traite={},{},[]\n",
    "#quelques troncons dont les valeurs sont soit connues soit à imposer à -99 après calcul\n",
    "dico_corection_calcul_3_voies=[[20,-99],[32,-99],[2909,38000,'mano'],[2792231,28359,'mano'],[2357,13000,'mano'],[88,14241,'mano'],[121,-99],[172,-99],[1104,20000,'mano'],[2020,15000],[4157,37000,'mano'],\n",
    " [4977,-99],[3829,27000,'mano'],[5148,19000,'mano'],[7078,-99],[5204,-99],[8238,-99],[11320,-99],[8020,-99],[1882,3500,'mano'],[3811,18000,'mano'],[2792253,-99],[3163,45000,'mano'],\n",
    " [278,-99],[2661,-99],[1679,-99],[2179,-99],[1468,2000,'mano'],[3254,12000,'mano'],[1601,-99],[2560,10000,'mano'],[3379,5000,'mano'],[582,-99],[1236,8000,'mano'],[1939,45000,'mano'],\n",
    " [214,-99],[5177,-99],[1627,-99],[6481,10000,'mano'],[1348,-99],[5603,-99],[1789,-99],[4579,-99],[4391,-99],[6213,-99],[1529,-99],[5467,3323,'mano'],[1797,-99],[1565,-99],[2577,1000,'mano'],\n",
    " [892,-99],[4014,-99],[1474,14000,'mano'],[6300,-99],[7209,2000,'mano'],[8368,14000,'mano'],[3510,5000,'mano'],[12864,8000,'mano'],[2253,800,'mano'],[7503,1942,'mano'],[4831,6000,'mano'],[6661,4000,'mano'],\n",
    " [7889,16000,'mano'], [2136,16000,'mano'],[3913,3000, 'mano'], [10667,17000,'mano'],[10098,16000,'mano'],[2280, 3000, 'mano'],[6580,6000,'mano'], [3126,20000,'mano'], [5486,10000,'mano'],[2792338,1000,'mano'],\n",
    " [2792339,7000,'mano'],[191,5000, 'mano']]\n",
    " \n",
    "i=0\n",
    "while liste_noeud_estim : \n",
    "    # pour chaque noeuds : \n",
    "      #calcul des troncons arrivants\n",
    "    print(f'debut boucle {datetime.now()}')\n",
    "    for j,num_noeud in enumerate(liste_noeud_estim) : \n",
    "        if j%200==0 : print(f'stocker valeur : {num_noeud} iter : {j}')\n",
    "        df_troncon_noeud=et.carac_troncon_noeud(gdf_rhv_rdpt_simple, gdf_base, graph_filaire_123_vertex,num_noeud,df_noeuds,lgn_rdpt)\n",
    "          #si tous les trafics du noeud sont déjà renseignés on passe\n",
    "        if (df_troncon_noeud.tmjo_2_sens!=-99).all() : \n",
    "            continue\n",
    "          #determiner si on est dans le cas d'une voie pouvant etre estimée par calcul (3 troncon dont 1 seul manquant) ou par analogie avec le MMM\n",
    "        type_calcul=et.type_estim(df_troncon_noeud)\n",
    "        if type_calcul=='calcul_3_voies' :\n",
    "            dico_noeud_3_voies[num_noeud]=df_troncon_noeud\n",
    " \n",
    "    print(f'nb noeud 3 voies {len(dico_noeud_3_voies)} ;  {datetime.now()}')\n",
    "    if len(dico_noeud_3_voies)==0 : break\n",
    "    \n",
    "    print(f'calcul des  valeur, debut :  {datetime.now()}')\n",
    "    for num_noeud, df_troncon_noeud in dico_noeud_3_voies.items() :\n",
    "        \n",
    "        gdf_rhv_rdpt_simple=verif_index(gdf_rhv_rdpt_simple,'idtronc')#Îsi idtronc est en index on le repasse dans les colonnes\n",
    "        if (df_troncon_noeud.tmjo_2_sens!=-99).all() : \n",
    "            continue\n",
    "        #calcul trafic\n",
    "        et.maj_trafic_3tronc(df_troncon_noeud)\n",
    "        df_update_traf=df_troncon_noeud[['idtronc','tmjo_2_sens','type_cpt']].set_index('idtronc').drop_duplicates()\n",
    "        df_update_traf.update(pd.DataFrame.from_records(dico_corection_calcul_3_voies, columns=['idtronc','tmjo_2_sens', 'type_cpt']).set_index('idtronc').fillna('NC'))\n",
    "          #mise à jour du fichier source\n",
    "        #try : \n",
    "        gdf_rhv_rdpt_simple=gdf_rhv_rdpt_simple.set_index('idtronc')\n",
    "        gdf_rhv_rdpt_simple.update(df_update_traf[['tmjo_2_sens','type_cpt']])\n",
    "        gdf_rhv_rdpt_simple.reset_index(inplace=True)\n",
    "        gdf_base=gdf_base.set_index('idtronc')\n",
    "        gdf_base.update(df_update_traf[['tmjo_2_sens','type_cpt']])\n",
    "        gdf_base.reset_index(inplace=True)\n",
    "        \n",
    "        liste_noeud_traite.append(num_noeud)\n",
    "    noeuds_estim, noeuds_grp, df_noeuds=et.noeuds_estimables(gdf_rhv_rdpt_simple)\n",
    "    liste_noeud_estim=[n for n in noeuds_estim.noeud.tolist() if n not in liste_noeud_traite]\n",
    "    dico_noeud_3_voies={}\n",
    "    i+=1\n",
    "    print(f'fin repetition num : {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_base['id_cpt_exp']=gdf_base['id_cpt_2_sens'].fillna('NC')\n",
    "gdf_base['id_cpt_exp']=gdf_base.apply(lambda x : ', '.join([str(a) for a in x['id_cpt_exp']]) \n",
    "                if isinstance(x['id_cpt_2_sens'],tuple) else str(x['id_cpt_2_sens']), axis=1)\n",
    "gdf_base.reset_index()[['id', 'ident', 'domanial', 'groupe', 'cat_dig', 'cat_rhv', 'passage',\n",
    "       'rggraph_nd', 'rggraph_na', 'rgraph_dbl', 'numero', 'cdate', 'mdate',\n",
    "       'id_ign', 'nature', 'sens', 'codevoie_d', 'importance', 'id_y','source', 'target',\n",
    "       'idtronc', 'geom','tmjo_2_sens','type_cpt', 'id_cpt_exp']].to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_123_calcul_3voies_v2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9315\n"
     ]
    }
   ],
   "source": [
    "for a in [9314,6404,6403, 8206, 9315] : \n",
    "    if a in df_noeuds.noeud.tolist() : \n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSUITE ON VA CHERCHER A TRAITER LES NOEUDS A PATIR DES DONNEES MMM\n",
    "gdf_test=gdf_base.copy()\n",
    "df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple5)[2:4]\n",
    "num_noeud=8826\n",
    "dico_erreur={}\n",
    "df_troncon_noeud=et.carac_troncon_noeud(gdf_rhv_rdpt_simple, gdf_test, graph_filaire_123_vertex,num_noeud,df_noeuds,lgn_rdpt)\n",
    "dico_troncons_noeud=et.creer_dico_troncons_noeud(df_troncon_noeud,gdf_rhv_rdpt_simple,gdf_base,lgn_rdpt,graph_filaire_123_vertex )\n",
    "matrice_rhv=et.matrice_troncon_noeud_rhv(df_troncon_noeud,num_noeud,lgn_rdpt,dico_troncons_noeud) \n",
    "try :\n",
    "    joint_fv_mmm_e2=et.estim_mmm_jointure_voies(matrice_rhv,cle_mmm_rhv)\n",
    "except et.PasCorrespondanceError : \n",
    "    dico_erreur[num_noeud]='PasCorrespondanceError'\n",
    "    df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple)[2:4]\n",
    "    liste_noeud_estim=[n for n in liste_noeud_estim if n not in liste_noeud_traite]\n",
    "try :\n",
    "    trafic_inconnus_prior_cat=et.isoler_trafic_inconnu(joint_fv_mmm_e2)\n",
    "except et.PasDeTraficInconnuError: \n",
    "    dico_erreur[num_noeud]='PasDeTraficInconnuError' \n",
    "    df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple)[2:4]\n",
    "    liste_noeud_estim=[n for n in liste_noeud_estim if n not in liste_noeud_traite]\n",
    "try :\n",
    "    trafc_rens=et.trafic_mmm(gdf_test,trafic_inconnus_prior_cat,mmm_simple,cle_mmm_rhv, df_troncon_noeud,dico_troncons_noeud,lgn_rdpt,dico_noeud,num_noeud)\n",
    "    df_update_traf=et.calcul_trafic_rhv_depuisMMM(trafc_rens).set_index('idtronc').rename(columns={'tmjo_2_sens_extrapol':'tmjo_2_sens'})\n",
    "except et.PasDeTraficError as e: \n",
    "    dico_erreur[num_noeud]=e \n",
    "    df_noeuds,liste_noeud_estim=et.noeuds_estimables(gdf_rhv_rdpt_simple)[2:4]\n",
    "    liste_noeud_estim=[n for n in liste_noeud_estim if n not in liste_noeud_traite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_ign</th>\n",
       "      <th>noeud</th>\n",
       "      <th>tmjo_2_sens</th>\n",
       "      <th>cat_rhv</th>\n",
       "      <th>rgraph_dbl</th>\n",
       "      <th>ident</th>\n",
       "      <th>type_noeud</th>\n",
       "      <th>idtronc</th>\n",
       "      <th>type_cpt</th>\n",
       "      <th>rgraph_dbl_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRONROUT37787</td>\n",
       "      <td>8826</td>\n",
       "      <td>33700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37787</td>\n",
       "      <td>d</td>\n",
       "      <td>462.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRONROUT37802</td>\n",
       "      <td>8826</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37802</td>\n",
       "      <td>d</td>\n",
       "      <td>557.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRONROUT37905</td>\n",
       "      <td>8826</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37905</td>\n",
       "      <td>d</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRONROUT30022</td>\n",
       "      <td>8826</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30022</td>\n",
       "      <td>a</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_ign  noeud  tmjo_2_sens cat_rhv  rgraph_dbl  ident type_noeud  \\\n",
       "0  TRONROUT37787  8826   33700.0      1       0.0         37787  d           \n",
       "1  TRONROUT37802  8826  -99.0         1       0.0         37802  d           \n",
       "2  TRONROUT37905  8826  -99.0         2       1.0         37905  d           \n",
       "3  TRONROUT30022  8826   6000.0       2       1.0         30022  a           \n",
       "\n",
       "   idtronc type_cpt  rgraph_dbl_2  \n",
       "0  462.0    NaN      1             \n",
       "1  557.0    NaN      1             \n",
       "2  1623.0   NaN      1             \n",
       "3  1025.0   NaN      1             "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_troncon_noeud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident_x</th>\n",
       "      <th>ident_y</th>\n",
       "      <th>idtronc_x</th>\n",
       "      <th>idtronc_y</th>\n",
       "      <th>tmjo_2_sens_x</th>\n",
       "      <th>tmjo_2_sens_y</th>\n",
       "      <th>cat_rhv_x</th>\n",
       "      <th>cat_rhv_y</th>\n",
       "      <th>type_cpt_x</th>\n",
       "      <th>type_cpt_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37787</td>\n",
       "      <td>37802</td>\n",
       "      <td>462.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>33700.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37787</td>\n",
       "      <td>37905</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>33700.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37787</td>\n",
       "      <td>30022</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>33700.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37802</td>\n",
       "      <td>37905</td>\n",
       "      <td>557.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37802</td>\n",
       "      <td>30022</td>\n",
       "      <td>557.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37905</td>\n",
       "      <td>30022</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ident_x ident_y  idtronc_x  idtronc_y  tmjo_2_sens_x  tmjo_2_sens_y  \\\n",
       "1   37787   37802   462.0      557.0      33700.0       -99.0            \n",
       "2   37787   37905   462.0      1623.0     33700.0       -99.0            \n",
       "3   37787   30022   462.0      1025.0     33700.0        6000.0          \n",
       "6   37802   37905   557.0      1623.0    -99.0          -99.0            \n",
       "7   37802   30022   557.0      1025.0    -99.0           6000.0          \n",
       "11  37905   30022   1623.0     1025.0    -99.0           6000.0          \n",
       "\n",
       "   cat_rhv_x cat_rhv_y type_cpt_x type_cpt_y  \n",
       "1   1         1         NaN        NaN        \n",
       "2   1         2         NaN        NaN        \n",
       "3   1         2         NaN        NaN        \n",
       "6   1         2         NaN        NaN        \n",
       "7   1         2         NaN        NaN        \n",
       "11  2         2         NaN        NaN        "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrice_rhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident_x</th>\n",
       "      <th>ident_y</th>\n",
       "      <th>idtronc_x</th>\n",
       "      <th>idtronc_y</th>\n",
       "      <th>tmjo_2_sens_x</th>\n",
       "      <th>tmjo_2_sens_y</th>\n",
       "      <th>cat_rhv_x</th>\n",
       "      <th>cat_rhv_y</th>\n",
       "      <th>type_cpt_x</th>\n",
       "      <th>type_cpt_y</th>\n",
       "      <th>NO_x</th>\n",
       "      <th>NO_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37787</td>\n",
       "      <td>37802</td>\n",
       "      <td>462.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>33700.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.145033e+09</td>\n",
       "      <td>7.240996e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37787</td>\n",
       "      <td>37905</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>33700.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.145033e+09</td>\n",
       "      <td>1.034980e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37787</td>\n",
       "      <td>30022</td>\n",
       "      <td>462.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>33700.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.145033e+09</td>\n",
       "      <td>8.653739e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37802</td>\n",
       "      <td>37905</td>\n",
       "      <td>557.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.240996e+08</td>\n",
       "      <td>1.034980e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37802</td>\n",
       "      <td>30022</td>\n",
       "      <td>557.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.240996e+08</td>\n",
       "      <td>8.653739e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37905</td>\n",
       "      <td>30022</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.034980e+09</td>\n",
       "      <td>8.653739e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident_x ident_y  idtronc_x  idtronc_y  tmjo_2_sens_x  tmjo_2_sens_y  \\\n",
       "0  37787   37802   462.0      557.0      33700.0       -99.0            \n",
       "1  37787   37905   462.0      1623.0     33700.0       -99.0            \n",
       "2  37787   30022   462.0      1025.0     33700.0        6000.0          \n",
       "3  37802   37905   557.0      1623.0    -99.0          -99.0            \n",
       "4  37802   30022   557.0      1025.0    -99.0           6000.0          \n",
       "5  37905   30022   1623.0     1025.0    -99.0           6000.0          \n",
       "\n",
       "  cat_rhv_x cat_rhv_y type_cpt_x type_cpt_y          NO_x          NO_y  \n",
       "0  1         1         NaN        NaN        2.145033e+09  7.240996e+08  \n",
       "1  1         2         NaN        NaN        2.145033e+09  1.034980e+09  \n",
       "2  1         2         NaN        NaN        2.145033e+09  8.653739e+08  \n",
       "3  1         2         NaN        NaN        7.240996e+08  1.034980e+09  \n",
       "4  1         2         NaN        NaN        7.240996e+08  8.653739e+08  \n",
       "5  2         2         NaN        NaN        1.034980e+09  8.653739e+08  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_fv_mmm_e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident_x</th>\n",
       "      <th>ident_y</th>\n",
       "      <th>idtronc_x</th>\n",
       "      <th>idtronc_y</th>\n",
       "      <th>tmjo_2_sens_x</th>\n",
       "      <th>tmjo_2_sens_y</th>\n",
       "      <th>cat_rhv_x</th>\n",
       "      <th>cat_rhv_y</th>\n",
       "      <th>type_cpt_x</th>\n",
       "      <th>type_cpt_y</th>\n",
       "      <th>NO_x</th>\n",
       "      <th>NO_y</th>\n",
       "      <th>idtronc_a_estim</th>\n",
       "      <th>diff_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37787</td>\n",
       "      <td>37802</td>\n",
       "      <td>462.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>33700.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.145033e+09</td>\n",
       "      <td>724099599.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37905</td>\n",
       "      <td>30022</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.034980e+09</td>\n",
       "      <td>865373854.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident_x ident_y  idtronc_x  idtronc_y  tmjo_2_sens_x  tmjo_2_sens_y  \\\n",
       "0  37787   37802   462.0      557.0      33700.0       -99.0            \n",
       "5  37905   30022   1623.0     1025.0    -99.0           6000.0          \n",
       "\n",
       "  cat_rhv_x cat_rhv_y type_cpt_x type_cpt_y          NO_x         NO_y  \\\n",
       "0  1         1         NaN        NaN        2.145033e+09  724099599.0   \n",
       "5  2         2         NaN        NaN        1.034980e+09  865373854.0   \n",
       "\n",
       "   idtronc_a_estim  diff_cat  \n",
       "0  557.0            0         \n",
       "5  1623.0           0         "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafic_inconnus_prior_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident_x</th>\n",
       "      <th>ident_y</th>\n",
       "      <th>idtronc_x</th>\n",
       "      <th>idtronc_y</th>\n",
       "      <th>tmjo_2_sens_x</th>\n",
       "      <th>tmjo_2_sens_y</th>\n",
       "      <th>cat_rhv_x</th>\n",
       "      <th>cat_rhv_y</th>\n",
       "      <th>type_cpt_x</th>\n",
       "      <th>type_cpt_y</th>\n",
       "      <th>NO_x</th>\n",
       "      <th>NO_y</th>\n",
       "      <th>idtronc_a_estim</th>\n",
       "      <th>diff_cat</th>\n",
       "      <th>tmja_tv_x</th>\n",
       "      <th>tmja_tv_y</th>\n",
       "      <th>traf_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37787</td>\n",
       "      <td>37802</td>\n",
       "      <td>462.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>33700.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.145033e+09</td>\n",
       "      <td>724099599.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>0</td>\n",
       "      <td>49006.35</td>\n",
       "      <td>46884.78</td>\n",
       "      <td>49006.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37905</td>\n",
       "      <td>30022</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.034980e+09</td>\n",
       "      <td>865373854.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6383.66</td>\n",
       "      <td>4884.85</td>\n",
       "      <td>4884.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident_x ident_y  idtronc_x  idtronc_y  tmjo_2_sens_x  tmjo_2_sens_y  \\\n",
       "0  37787   37802   462.0      557.0      33700.0       -99.0            \n",
       "1  37905   30022   1623.0     1025.0    -99.0           6000.0          \n",
       "\n",
       "  cat_rhv_x cat_rhv_y type_cpt_x type_cpt_y          NO_x         NO_y  \\\n",
       "0  1         1         NaN        NaN        2.145033e+09  724099599.0   \n",
       "1  2         2         NaN        NaN        1.034980e+09  865373854.0   \n",
       "\n",
       "   idtronc_a_estim  diff_cat  tmja_tv_x  tmja_tv_y  traf_max  \n",
       "0  557.0            0         49006.35   46884.78   49006.35  \n",
       "1  1623.0           0         6383.66    4884.85    4884.85   "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trafc_rens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmjo_2_sens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idtronc</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>557.0</th>\n",
       "      <td>32241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623.0</th>\n",
       "      <td>7840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tmjo_2_sens\n",
       "idtronc             \n",
       "557.0    32241      \n",
       "1623.0   7840       "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_update_traf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_calcul['id_cpt_exp']=gdf_calcul['id_cpt_2_sens'].fillna('NC')\n",
    "gdf_calcul['id_cpt_exp']=gdf_calcul.apply(lambda x : ', '.join([str(a) for a in x['id_cpt_exp']]) \n",
    "                if isinstance(x['id_cpt_2_sens'],tuple) else str(x['id_cpt_2_sens']), axis=1)\n",
    "gdf_calcul.reset_index()[['id', 'ident', 'domanial', 'groupe', 'cat_dig', 'cat_rhv', 'passage',\n",
    "       'rggraph_nd', 'rggraph_na', 'rgraph_dbl', 'numero', 'cdate', 'mdate',\n",
    "       'id_ign', 'nature', 'sens', 'codevoie_d', 'importance', 'id_y','source', 'target',\n",
    "       'idtronc', 'geom','tmjo_2_sens','type_cpt', 'id_cpt_exp']].to_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\gdf_rhv_trafic_123_calcul_mmm_v5.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_base=gdf_traf_tot.copy()\n",
    "lgn_rdpt, dico_noeud, gdf_rhv_rdpt_simple=donnees_tot_rd_pt(gdf_base, 'local_otv','linearisation_bm', 'graph_rhv_123_v2','graph_rhv_123_v2_vertices_pgr')\n",
    "gdf_rhv_rdpt_simple5=gdf_rhv_rdpt_simple.copy()\n",
    "\n",
    "et.calculer_trafic_3voies(gdf_base,gdf_rhv_rdpt_simple5,lgn_rdpt,graph_filaire_123_vertex)\n",
    "\n",
    "gdf_calcul=gdf_base.copy()\n",
    "gdf_rhv_rdpt_simple2=gdf_rhv_rdpt_simple5.copy()\n",
    "et.calculer_trafic_mmm(gdf_calcul, gdf_rhv_rdpt_simple2,lgn_rdpt,graph_filaire_123_vertex,mmm_simple,cle_mmm_rhv,dico_noeud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voies catégorie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer le fichier de batiments nettoye hors BM\n",
    "bati=gp.read_file(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\bati.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martin.schoreisz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\function_base.py:2167: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    }
   ],
   "source": [
    "#plus proche voisin sur la base de tout le rhv route\n",
    "coreesp_bati=plus_proche_voisin(bati,gdf_rhv_groupe,40,'ID','ident')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?   y\n"
     ]
    }
   ],
   "source": [
    "%reset_selective bati_limite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreesp_bati.to_csv(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\ppv_bati-route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreesp_bati2=pd.read_csv(r'D:\\temp\\Linearisation_BM\\C19SA0101\\C19SA0101\\Doc_travail\\Donnees_produites\\Donnees\\bati\\ppv_bati-route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    16357                   \n",
       "ID            BATIMENT0000000253984448\n",
       "ident         46893                   \n",
       "Name: 10000, dtype: object"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coreesp_bati2.iloc[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682117</th>\n",
       "      <td>BATIMENT0000000253435871</td>\n",
       "      <td>33348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682140</th>\n",
       "      <td>BATIMENT0000000254037708</td>\n",
       "      <td>34700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682160</th>\n",
       "      <td>BATIMENT0000000253435860</td>\n",
       "      <td>33345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682170</th>\n",
       "      <td>BATIMENT0000000255620399</td>\n",
       "      <td>3577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682172</th>\n",
       "      <td>BATIMENT0000000051153785</td>\n",
       "      <td>45711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID  ident\n",
       "682117  BATIMENT0000000253435871  33348\n",
       "682140  BATIMENT0000000254037708  34700\n",
       "682160  BATIMENT0000000253435860  33345\n",
       "682170  BATIMENT0000000255620399  3577 \n",
       "682172  BATIMENT0000000051153785  45711"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coreesp_bati.tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
